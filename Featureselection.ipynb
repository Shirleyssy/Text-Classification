{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Featureselection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Equy55YG_Bgo"
      },
      "source": [
        "# Feature selection\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EehD11mVGOTq",
        "outputId": "ff56cc04-1edd-47f3-ca63-3c6675fc3115",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction import text\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk import word_tokenize\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from nltk import word_tokenize          \n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "def get_wordnet_pos(word):\n",
        "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
        "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
        "    tag_dict = {\"J\": wordnet.ADJ,\n",
        "                \"N\": wordnet.NOUN,\n",
        "                \"V\": wordnet.VERB,\n",
        "                \"R\": wordnet.ADV}\n",
        "    return tag_dict.get(tag, wordnet.NOUN)\n",
        "class New_LemmaTokenizer:\n",
        "     def __init__(self):\n",
        "       self.wnl = WordNetLemmatizer()\n",
        "     def __call__(self, doc):\n",
        "       return [self.wnl.lemmatize(t,pos =get_wordnet_pos(t)) for t in word_tokenize(doc) if t.isalpha()]\n",
        "class StemTokenizer:\n",
        "     def __init__(self):\n",
        "       self.wnl =PorterStemmer()\n",
        "     def __call__(self, doc):\n",
        "       return [self.wnl.stem(t) for t in word_tokenize(doc) if t.isalpha()]\n",
        "\n",
        "class NBN():\n",
        "  def __init__(self, X, Y):\n",
        "    self.X = X\n",
        "    self.Y = Y\n",
        "    self.topic_portion = []\n",
        "    self.freq_feature = np.zeros((8,self.X.shape[1]))\n",
        "\n",
        "  def build_NBN(self):\n",
        "    topics = np.array([['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']])\n",
        "    each_topic = []\n",
        "    topic_portion = []\n",
        "\n",
        "    for topic in topics:\n",
        "      each_topic.append((sum([i == topic for i in self.Y]))[0])\n",
        "      topic_portion.append((sum([i == topic for i in self.Y])/len(self.Y))[0])\n",
        "    #print(each_topic)\n",
        "    #print(topic_portion)\n",
        "    self.topic_portion = topic_portion\n",
        "\n",
        "    i=0\n",
        "    j=0\n",
        "    #maxFeatures = 200\n",
        "    sum_feature = np.zeros((8,self.X.shape[1]))\n",
        "    freq_feature = np.zeros((8,self.X.shape[1]))\n",
        "    for count in each_topic:\n",
        "      sum_feature[i,:] = np.sum(self.X[j:j+count,:],axis=0)\n",
        "      freq_feature[i,:] = (np.sum(self.X[j:j+count,:],axis=0)+1)/(count+2)\n",
        "      #freq_feature[i,:] = (np.sum(trains[j:j+count,:],axis=0))/(count)\n",
        "      i=i+1\n",
        "      j=j+count\n",
        "     \n",
        "    self.freq_feature = freq_feature\n",
        "    #print(freq_feature)\n",
        "    return topic_portion,freq_feature,topics\n",
        "\n",
        "\n",
        "  def predict(self,X):\n",
        "    prob = np.ones((1,8))\n",
        "    for j in np.arange(X.shape[1]):\n",
        "        prob = np.multiply(np.multiply(np.power(self.freq_feature[:,j],X[0,j]),np.power(1-self.freq_feature[:,j],1-X[0,j])),prob)\n",
        "    prob = np.log(np.multiply(self.topic_portion,prob))\n",
        "    category = np.argmax(prob)\n",
        "    \n",
        "    return category\n",
        "\n",
        "def Accu_eval(X,Y,topics):\n",
        "  n = X.shape[0]\n",
        "  result = np.zeros((1,n))\n",
        "  for i in np.arange(n):\n",
        "    result[0,i] = NBN1.predict(X[i,:])\n",
        "\n",
        "  #print(result)\n",
        "\n",
        "  Y_original = []\n",
        "  correct = 0\n",
        "  for i in np.arange(n):\n",
        "    Y_original.append(topics.tolist().index([Y[i]]))\n",
        "    #Y_original.append(topics.index(Y[i]))\n",
        "    if topics.tolist().index([Y[i]])-result[0,i] == 0:\n",
        "      \n",
        "      correct = correct+1\n",
        "\n",
        "  #print(Y_original)\n",
        "  return correct/n, result\n",
        "\n",
        "\n",
        "def trans_train(X):\n",
        "  Z = X\n",
        "  for i in np.arange(X.shape[0]):\n",
        "    for j in np.arange(X.shape[1]):\n",
        "      if X[i,j] != 0:\n",
        "        Z[i,j] = 1\n",
        "  return Z\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCRtJxHM_eCh"
      },
      "source": [
        "information_gain"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHPfqdnv_GFq",
        "outputId": "c3e0eaa3-1e15-470c-b726-e0a9df80e6cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "my_stop_words = text.ENGLISH_STOP_WORDS\n",
        "#import datasets\n",
        "#train = pd.read_csv('train_no_gamenews_computers.csv')\n",
        "train = pd.read_csv('train.csv')\n",
        "n=train.shape[0]\n",
        "#print(n)\n",
        "s=10000\n",
        "\n",
        "skip = sorted(random.sample(range(1,n+1),n-s))\n",
        "#print(len(skip))\n",
        "train = pd.read_csv('train.csv',skiprows=skip)\n",
        "test = pd.read_csv('test.csv')\n",
        "#print(train.shape[0])\n",
        "\n",
        "X = pd.DataFrame(train['body'])\n",
        "Y = pd.DataFrame(train['subreddit'])\n",
        "X = X['body'].tolist() \n",
        "Y = Y['subreddit'].tolist()\n",
        "Y_ = np.array(Y)\n",
        "X_ = np.array(X)\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn import metrics\n",
        "vectorizerfeature = CountVectorizer(min_df =1,binary=True,stop_words = my_stop_words, tokenizer=StemTokenizer())\n",
        "vectors_train = vectorizerfeature.fit_transform(X_)\n",
        "label = Y_\n",
        "\n",
        "from scipy.stats import entropy\n",
        "import pandas as pd\n",
        "def information_gain(members, split):\n",
        "\n",
        "    entropy_before = entropy(members.value_counts(normalize=True))\n",
        "    split.name = 'split'\n",
        "    members.name = 'members'\n",
        "    grouped_distrib = members.groupby(split).value_counts(normalize=True).reset_index(name='count').pivot_table(index='split', columns='members', values='count').fillna(0)\n",
        "    entropy_after = entropy(grouped_distrib, axis=1)\n",
        "    entropy_after *= split.value_counts(sort=False, normalize=True)\n",
        "    return entropy_before - entropy_after.sum()\n",
        "\n",
        "ig=[]\n",
        "for i in range(vectors_train.todense().shape[1]):\n",
        "  x=vectors_train.todense()\n",
        "  x0 = x[:, i]\n",
        "  x0=np.array(x0).flatten()\n",
        "  x00 = pd.Series(x0.tolist())\n",
        "  label0= pd.Series(label.tolist())\n",
        "  ig.append(information_gain(label0, x00))\n",
        "#print(ig)\n",
        "print(len(ig))\n",
        "precis = []\n",
        "f1 = []\n",
        "reca= []\n",
        "for feanum in range(5):\n",
        "  import heapq\n",
        "  lis= ig.copy()\n",
        "  n=(feanum+1)*1000\n",
        "  max_number = heapq.nlargest(n, lis) \n",
        "  max_index = []\n",
        "  for t in max_number:\n",
        "      index = lis.index(t)\n",
        "      max_index.append(index)\n",
        "      lis[index] = 0\n",
        "      \n",
        "\n",
        "\n",
        "  voca=[]\n",
        "  for i in max_index:\n",
        "    voca.append(vectorizerfeature.get_feature_names()[i])\n",
        "  voca2 = sorted(set(voca),key=voca.index)\n",
        "\n",
        "  vectorizer = CountVectorizer(vocabulary=voca2,binary=True,stop_words = my_stop_words, tokenizer=StemTokenizer())\n",
        "  vectors_train = vectorizer.fit_transform(X_)\n",
        "  vectors_train.todense()\n",
        "\n",
        "  kf = KFold(n_splits=6,shuffle=True)\n",
        "  kf.get_n_splits(X_)\n",
        "  accuracy = []\n",
        "  f1_sc = []\n",
        "  recall_sc= []\n",
        "  X_train_ = []\n",
        "  y_train_ = []\n",
        "  X_test_ = []\n",
        "  y_test_ = []\n",
        "  for train_index, test_index in kf.split(X_):\n",
        "\n",
        "    X_train, X_test = X_[train_index], X_[test_index]\n",
        "    y_train, y_test = Y_[train_index].tolist(), Y_[test_index].tolist()\n",
        "    X_train_ = []\n",
        "    X_test_ = []\n",
        "\n",
        "    print(type(X_train))\n",
        "    X_train = X_train.tolist()\n",
        "    X_test = X_test.tolist()\n",
        "    vectorizer = CountVectorizer(vocabulary=voca2,binary=True, tokenizer=StemTokenizer())\n",
        "    vectors_train = vectorizer.fit_transform(X_train)\n",
        "    vectors_test = vectorizer.transform(X_test)\n",
        "    print(vectors_train.shape)\n",
        "    trains = vectors_train.todense()\n",
        "    tests = vectors_test.todense()\n",
        "    print(len(tests))\n",
        "    print(len(y_test))\n",
        "\n",
        "    NBN1 = NBN(trains, y_train)\n",
        "    topic_portion,freq_feature,topics = NBN1.build_NBN()\n",
        "    print(topics.tolist())\n",
        "    accu, result = Accu_eval(tests,y_test,topics)\n",
        "    n=len(y_test)\n",
        "    y_test0=[]\n",
        "    for i in range(n):\n",
        "      y_test0.append(topics.tolist().index([y_test[i]]))\n",
        "    accuracy.append(metrics.precision_score(y_test0, result[0], average='weighted'))\n",
        "    f1_sc.append(metrics.f1_score(y_test0, result[0], average='weighted'))\n",
        "    recall_sc.append(metrics.recall_score(y_test0, result[0], average='weighted'))\n",
        "    print(metrics.classification_report(y_test0, result[0]))\n",
        "  print(np.mean(accuracy))\n",
        "  print(np.mean(f1_sc))\n",
        "  print(np.mean(recall_sc))\n",
        "  precis.append(np.mean(accuracy))\n",
        "  f1.append(np.mean(f1_sc))\n",
        "  reca.append(np.mean(recall_sc))\n",
        "print('precision_score',precis)\n",
        "print('f1_score',f1)\n",
        "print('recall_score',reca)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1947\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "(83, 10)\n",
            "17\n",
            "17\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         1\n",
            "           2       0.50      1.00      0.67         3\n",
            "           3       1.00      0.25      0.40         4\n",
            "           4       0.86      1.00      0.92         6\n",
            "           5       0.00      0.00      0.00         2\n",
            "           6       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.59        17\n",
            "   macro avg       0.39      0.38      0.33        17\n",
            "weighted avg       0.63      0.59      0.54        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(83, 10)\n",
            "17\n",
            "17\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      0.71      0.83         7\n",
            "         1.0       1.00      1.00      1.00         1\n",
            "         2.0       0.20      1.00      0.33         1\n",
            "         3.0       1.00      1.00      1.00         1\n",
            "         4.0       0.50      0.50      0.50         4\n",
            "         5.0       0.00      0.00      0.00         1\n",
            "         6.0       0.00      0.00      0.00         0\n",
            "         7.0       0.00      0.00      0.00         2\n",
            "\n",
            "    accuracy                           0.59        17\n",
            "   macro avg       0.46      0.53      0.46        17\n",
            "weighted avg       0.66      0.59      0.60        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(83, 10)\n",
            "17\n",
            "17\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.33      0.25      0.29         4\n",
            "         1.0       1.00      1.00      1.00         1\n",
            "         2.0       0.67      1.00      0.80         2\n",
            "         3.0       0.67      1.00      0.80         2\n",
            "         4.0       0.80      1.00      0.89         4\n",
            "         5.0       0.00      0.00      0.00         0\n",
            "         6.0       1.00      0.33      0.50         3\n",
            "         7.0       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.65        17\n",
            "   macro avg       0.56      0.57      0.53        17\n",
            "weighted avg       0.66      0.65      0.61        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(83, 10)\n",
            "17\n",
            "17\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67         2\n",
            "           1       1.00      1.00      1.00         1\n",
            "           2       0.67      1.00      0.80         2\n",
            "           3       0.40      1.00      0.57         2\n",
            "           4       1.00      0.80      0.89         5\n",
            "           5       0.00      0.00      0.00         1\n",
            "           6       0.00      0.00      0.00         3\n",
            "           7       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.65        17\n",
            "   macro avg       0.45      0.60      0.49        17\n",
            "weighted avg       0.54      0.65      0.56        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(84, 10)\n",
            "16\n",
            "16\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.60      1.00      0.75         3\n",
            "         1.0       1.00      1.00      1.00         1\n",
            "         2.0       0.25      0.33      0.29         3\n",
            "         3.0       0.00      0.00      0.00         0\n",
            "         4.0       0.75      0.75      0.75         4\n",
            "         5.0       0.00      0.00      0.00         1\n",
            "         6.0       0.00      0.00      0.00         2\n",
            "         7.0       0.00      0.00      0.00         2\n",
            "\n",
            "    accuracy                           0.50        16\n",
            "   macro avg       0.33      0.39      0.35        16\n",
            "weighted avg       0.41      0.50      0.44        16\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(84, 10)\n",
            "16\n",
            "16\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         3\n",
            "           1       1.00      0.40      0.57         5\n",
            "           2       0.00      0.00      0.00         1\n",
            "           3       0.00      0.00      0.00         3\n",
            "           4       0.50      0.50      0.50         2\n",
            "           6       1.00      0.50      0.67         2\n",
            "\n",
            "    accuracy                           0.44        16\n",
            "   macro avg       0.58      0.40      0.46        16\n",
            "weighted avg       0.69      0.44      0.51        16\n",
            "\n",
            "0.5963045634920634\n",
            "0.5439009417869711\n",
            "0.5680147058823529\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "(83, 20)\n",
            "17\n",
            "17\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67         1\n",
            "           1       1.00      0.50      0.67         2\n",
            "           2       0.33      0.50      0.40         2\n",
            "           3       0.50      0.25      0.33         4\n",
            "           4       0.50      1.00      0.67         4\n",
            "           6       0.00      0.00      0.00         4\n",
            "\n",
            "    accuracy                           0.47        17\n",
            "   macro avg       0.47      0.54      0.46        17\n",
            "weighted avg       0.42      0.47      0.40        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n",
            "(83, 20)\n",
            "17\n",
            "17\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.25      1.00      0.40         1\n",
            "           1       0.00      0.00      0.00         2\n",
            "           2       0.00      0.00      0.00         1\n",
            "           4       0.86      0.86      0.86         7\n",
            "           5       0.00      0.00      0.00         2\n",
            "           6       0.75      1.00      0.86         3\n",
            "           7       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.59        17\n",
            "   macro avg       0.27      0.41      0.30        17\n",
            "weighted avg       0.50      0.59      0.53        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(83, 20)\n",
            "17\n",
            "17\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      0.71      0.83         7\n",
            "         1.0       1.00      1.00      1.00         1\n",
            "         2.0       0.00      0.00      0.00         3\n",
            "         3.0       1.00      0.50      0.67         2\n",
            "         4.0       0.43      1.00      0.60         3\n",
            "         6.0       0.00      0.00      0.00         0\n",
            "         7.0       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           0.65        17\n",
            "   macro avg       0.63      0.60      0.59        17\n",
            "weighted avg       0.72      0.65      0.65        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(83, 20)\n",
            "17\n",
            "17\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         1\n",
            "           1       1.00      1.00      1.00         3\n",
            "           2       0.67      0.67      0.67         3\n",
            "           3       1.00      1.00      1.00         2\n",
            "           4       0.60      1.00      0.75         3\n",
            "           5       1.00      0.50      0.67         2\n",
            "           6       0.50      0.50      0.50         2\n",
            "           7       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.76        17\n",
            "   macro avg       0.72      0.71      0.70        17\n",
            "weighted avg       0.75      0.76      0.74        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(84, 20)\n",
            "16\n",
            "16\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         5\n",
            "           2       0.00      0.00      0.00         1\n",
            "           3       1.00      0.33      0.50         3\n",
            "           4       0.67      0.80      0.73         5\n",
            "           5       1.00      1.00      1.00         1\n",
            "           7       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.69        16\n",
            "   macro avg       0.61      0.52      0.54        16\n",
            "weighted avg       0.77      0.69      0.70        16\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(84, 20)\n",
            "16\n",
            "16\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.40      0.50         5\n",
            "           1       1.00      1.00      1.00         1\n",
            "           2       0.50      0.50      0.50         2\n",
            "           3       0.33      1.00      0.50         1\n",
            "           4       0.43      1.00      0.60         3\n",
            "           6       0.00      0.00      0.00         2\n",
            "           7       0.00      0.00      0.00         2\n",
            "\n",
            "    accuracy                           0.50        16\n",
            "   macro avg       0.42      0.56      0.44        16\n",
            "weighted avg       0.43      0.50      0.42        16\n",
            "\n",
            "0.6004260037348272\n",
            "0.5723413228927935\n",
            "0.6096813725490197\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "(83, 30)\n",
            "17\n",
            "17\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      1.00      0.89         4\n",
            "           1       1.00      0.33      0.50         3\n",
            "           2       1.00      0.75      0.86         4\n",
            "           3       1.00      1.00      1.00         1\n",
            "           4       0.60      1.00      0.75         3\n",
            "           6       1.00      1.00      1.00         2\n",
            "\n",
            "    accuracy                           0.82        17\n",
            "   macro avg       0.90      0.85      0.83        17\n",
            "weighted avg       0.88      0.82      0.81        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n",
            "(83, 30)\n",
            "17\n",
            "17\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.43      0.50         7\n",
            "           1       1.00      1.00      1.00         1\n",
            "           2       0.33      1.00      0.50         1\n",
            "           3       1.00      1.00      1.00         1\n",
            "           4       0.33      1.00      0.50         2\n",
            "           5       0.00      0.00      0.00         3\n",
            "           6       1.00      0.50      0.67         2\n",
            "\n",
            "    accuracy                           0.53        17\n",
            "   macro avg       0.61      0.70      0.60        17\n",
            "weighted avg       0.54      0.53      0.49        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(83, 30)\n",
            "17\n",
            "17\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         2\n",
            "         1.0       0.00      0.00      0.00         1\n",
            "         2.0       0.00      0.00      0.00         0\n",
            "         3.0       0.67      0.50      0.57         4\n",
            "         4.0       1.00      0.75      0.86         8\n",
            "         6.0       0.00      0.00      0.00         1\n",
            "         7.0       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.59        17\n",
            "   macro avg       0.38      0.32      0.35        17\n",
            "weighted avg       0.75      0.59      0.66        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(83, 30)\n",
            "17\n",
            "17\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.33      1.00      0.50         1\n",
            "           1       1.00      0.50      0.67         2\n",
            "           2       0.50      0.33      0.40         3\n",
            "           3       0.60      1.00      0.75         3\n",
            "           4       0.60      0.75      0.67         4\n",
            "           5       0.00      0.00      0.00         1\n",
            "           6       0.00      0.00      0.00         1\n",
            "           7       0.00      0.00      0.00         2\n",
            "\n",
            "    accuracy                           0.53        17\n",
            "   macro avg       0.38      0.45      0.37        17\n",
            "weighted avg       0.47      0.53      0.47        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(84, 30)\n",
            "16\n",
            "16\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      0.67      0.80         3\n",
            "         1.0       1.00      1.00      1.00         1\n",
            "         2.0       0.00      0.00      0.00         1\n",
            "         3.0       0.50      1.00      0.67         1\n",
            "         4.0       0.57      1.00      0.73         4\n",
            "         5.0       0.00      0.00      0.00         0\n",
            "         6.0       0.00      0.00      0.00         5\n",
            "         7.0       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.50        16\n",
            "   macro avg       0.38      0.46      0.40        16\n",
            "weighted avg       0.42      0.50      0.44        16\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(84, 30)\n",
            "16\n",
            "16\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      0.67      0.80         3\n",
            "         1.0       1.00      1.00      1.00         1\n",
            "         2.0       0.00      0.00      0.00         3\n",
            "         3.0       0.00      0.00      0.00         2\n",
            "         4.0       0.40      1.00      0.57         4\n",
            "         5.0       0.00      0.00      0.00         1\n",
            "         6.0       0.00      0.00      0.00         0\n",
            "         7.0       0.00      0.00      0.00         2\n",
            "\n",
            "    accuracy                           0.44        16\n",
            "   macro avg       0.30      0.33      0.30        16\n",
            "weighted avg       0.35      0.44      0.36        16\n",
            "\n",
            "0.5692139355742297\n",
            "0.5354228560110914\n",
            "0.5680147058823529\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "(83, 40)\n",
            "17\n",
            "17\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      0.50      0.67         4\n",
            "         1.0       1.00      1.00      1.00         1\n",
            "         2.0       0.00      0.00      0.00         2\n",
            "         3.0       0.50      0.33      0.40         3\n",
            "         4.0       0.50      0.75      0.60         4\n",
            "         5.0       0.00      0.00      0.00         0\n",
            "         6.0       1.00      0.33      0.50         3\n",
            "\n",
            "    accuracy                           0.47        17\n",
            "   macro avg       0.57      0.42      0.45        17\n",
            "weighted avg       0.68      0.47      0.52        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(83, 40)\n",
            "17\n",
            "17\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.75      0.75      0.75         4\n",
            "         1.0       1.00      1.00      1.00         1\n",
            "         2.0       0.00      0.00      0.00         0\n",
            "         3.0       1.00      0.50      0.67         2\n",
            "         4.0       0.71      1.00      0.83         5\n",
            "         5.0       1.00      1.00      1.00         1\n",
            "         6.0       0.00      0.00      0.00         3\n",
            "         7.0       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           0.71        17\n",
            "   macro avg       0.68      0.66      0.66        17\n",
            "weighted avg       0.68      0.71      0.68        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(83, 40)\n",
            "17\n",
            "17\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      0.40      0.57         5\n",
            "         1.0       1.00      1.00      1.00         2\n",
            "         2.0       0.00      0.00      0.00         4\n",
            "         3.0       0.00      0.00      0.00         0\n",
            "         4.0       0.30      1.00      0.46         3\n",
            "         5.0       0.00      0.00      0.00         1\n",
            "         6.0       1.00      1.00      1.00         1\n",
            "         7.0       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.47        17\n",
            "   macro avg       0.41      0.42      0.38        17\n",
            "weighted avg       0.52      0.47      0.43        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(83, 40)\n",
            "17\n",
            "17\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         1\n",
            "           1       1.00      0.50      0.67         2\n",
            "           2       0.33      1.00      0.50         2\n",
            "           3       0.50      0.67      0.57         3\n",
            "           4       0.50      0.50      0.50         4\n",
            "           6       0.00      0.00      0.00         2\n",
            "           7       0.00      0.00      0.00         3\n",
            "\n",
            "    accuracy                           0.47        17\n",
            "   macro avg       0.48      0.52      0.46        17\n",
            "weighted avg       0.42      0.47      0.41        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(84, 40)\n",
            "16\n",
            "16\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      1.00      0.75         3\n",
            "           1       0.00      0.00      0.00         3\n",
            "           3       1.00      1.00      1.00         3\n",
            "           4       0.33      1.00      0.50         2\n",
            "           5       0.00      0.00      0.00         2\n",
            "           6       0.50      0.50      0.50         2\n",
            "           7       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.56        16\n",
            "   macro avg       0.35      0.50      0.39        16\n",
            "weighted avg       0.40      0.56      0.45        16\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(84, 40)\n",
            "16\n",
            "16\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.33      0.50         3\n",
            "           2       1.00      1.00      1.00         4\n",
            "           3       1.00      1.00      1.00         1\n",
            "           4       0.78      1.00      0.88         7\n",
            "           5       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           0.88        16\n",
            "   macro avg       0.96      0.87      0.88        16\n",
            "weighted avg       0.90      0.88      0.85        16\n",
            "\n",
            "0.6015308901338313\n",
            "0.5562326613337644\n",
            "0.5925245098039216\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "(83, 50)\n",
            "17\n",
            "17\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.50      0.50         2\n",
            "           1       1.00      1.00      1.00         2\n",
            "           2       1.00      0.25      0.40         4\n",
            "           3       1.00      0.75      0.86         4\n",
            "           4       0.25      1.00      0.40         2\n",
            "           7       1.00      0.33      0.50         3\n",
            "\n",
            "    accuracy                           0.59        17\n",
            "   macro avg       0.79      0.64      0.61        17\n",
            "weighted avg       0.85      0.59      0.61        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n",
            "(83, 50)\n",
            "17\n",
            "17\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.40      0.57         5\n",
            "           2       0.25      0.50      0.33         2\n",
            "           3       1.00      0.33      0.50         3\n",
            "           4       0.20      1.00      0.33         2\n",
            "           5       0.00      0.00      0.00         3\n",
            "           6       0.00      0.00      0.00         1\n",
            "           7       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.35        17\n",
            "   macro avg       0.35      0.32      0.25        17\n",
            "weighted avg       0.52      0.35      0.33        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(83, 50)\n",
            "17\n",
            "17\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00         2\n",
            "         1.0       1.00      0.33      0.50         3\n",
            "         2.0       1.00      1.00      1.00         3\n",
            "         3.0       0.00      0.00      0.00         0\n",
            "         4.0       0.75      1.00      0.86         6\n",
            "         5.0       1.00      1.00      1.00         1\n",
            "         6.0       0.00      0.00      0.00         0\n",
            "         7.0       0.00      0.00      0.00         2\n",
            "\n",
            "    accuracy                           0.76        17\n",
            "   macro avg       0.59      0.54      0.54        17\n",
            "weighted avg       0.79      0.76      0.74        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(83, 50)\n",
            "17\n",
            "17\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.50      1.00      0.67         2\n",
            "         2.0       0.00      0.00      0.00         0\n",
            "         3.0       1.00      0.67      0.80         3\n",
            "         4.0       0.80      0.50      0.62         8\n",
            "         5.0       1.00      1.00      1.00         1\n",
            "         6.0       1.00      0.33      0.50         3\n",
            "\n",
            "    accuracy                           0.59        17\n",
            "   macro avg       0.72      0.58      0.60        17\n",
            "weighted avg       0.85      0.59      0.66        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(84, 50)\n",
            "16\n",
            "16\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.86      0.92         7\n",
            "           1       1.00      0.50      0.67         2\n",
            "           2       0.00      0.00      0.00         1\n",
            "           3       0.33      1.00      0.50         1\n",
            "           4       0.25      1.00      0.40         1\n",
            "           6       1.00      0.25      0.40         4\n",
            "\n",
            "    accuracy                           0.62        16\n",
            "   macro avg       0.60      0.60      0.48        16\n",
            "weighted avg       0.85      0.62      0.64        16\n",
            "\n",
            "<class 'numpy.ndarray'>\n",
            "(84, 50)\n",
            "16\n",
            "16\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         2\n",
            "           1       1.00      1.00      1.00         2\n",
            "           2       0.25      0.50      0.33         2\n",
            "           3       0.50      1.00      0.67         1\n",
            "           4       0.62      0.83      0.71         6\n",
            "           6       0.00      0.00      0.00         3\n",
            "\n",
            "    accuracy                           0.56        16\n",
            "   macro avg       0.40      0.56      0.45        16\n",
            "weighted avg       0.42      0.56      0.48        16\n",
            "\n",
            "0.7147467320261439\n",
            "0.5769789646627883\n",
            "0.5802696078431372\n",
            "precision_score [0.5963045634920634, 0.6004260037348272, 0.5692139355742297, 0.6015308901338313, 0.7147467320261439]\n",
            "f1_score [0.5439009417869711, 0.5723413228927935, 0.5354228560110914, 0.5562326613337644, 0.5769789646627883]\n",
            "recall_score [0.5680147058823529, 0.6096813725490197, 0.5680147058823529, 0.5925245098039216, 0.5802696078431372]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sN2kFo0j_sOx"
      },
      "source": [
        "log likilhood ratio"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttog55Db_m6S",
        "outputId": "8e12846f-1186-402d-88be-27707b7fe900",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "my_stop_words = text.ENGLISH_STOP_WORDS\n",
        "#import datasets\n",
        "#train = pd.read_csv('train_no_gamenews_computers.csv')\n",
        "train = pd.read_csv('train.csv')\n",
        "n=train.shape[0]\n",
        "#print(n)\n",
        "s=10000\n",
        "\n",
        "skip = sorted(random.sample(range(1,n+1),n-s))\n",
        "#print(len(skip))\n",
        "train = pd.read_csv('train.csv',skiprows=skip)\n",
        "test = pd.read_csv('test.csv')\n",
        "#print(train.shape[0])\n",
        "\n",
        "X = pd.DataFrame(train['body'])\n",
        "Y = pd.DataFrame(train['subreddit'])\n",
        "X = X['body'].tolist() \n",
        "Y = Y['subreddit'].tolist()\n",
        "Y_ = np.array(Y)\n",
        "X_ = np.array(X)\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn import metrics\n",
        "vectorizerfeature = CountVectorizer(min_df =1,binary=True,stop_words = my_stop_words, tokenizer=StemTokenizer())\n",
        "vectors_train = vectorizerfeature.fit_transform(X_)\n",
        "label = Y_\n",
        "\n",
        "import math\n",
        "Y_original = []\n",
        "topics =['rpg', 'anime', 'datascience', 'hardware', 'cars', 'gamernews', 'gamedev', 'computers']\n",
        "for i in range(vectors_train.todense().shape[0]):\n",
        "  Y_original.append(topics.index(label[i]))\n",
        "ll=np.zeros((vectors_train.todense().shape[1], len(topics)))\n",
        "for i in range(len(topics)):\n",
        "  for j in range(vectors_train.todense().shape[1]): #每个词\n",
        "    x=vectors_train.todense()\n",
        "    x0 = x[:, j]\n",
        "    A=0\n",
        "    B=0\n",
        "    C=0\n",
        "    D=0\n",
        "    for jj in range(vectors_train.todense().shape[0]):\n",
        "      if x0[jj]!=0:\n",
        "        if Y_original[jj]==i:\n",
        "          A=A+1\n",
        "        else:\n",
        "          B=B+1\n",
        "      else:\n",
        "        if Y_original[jj]==i:\n",
        "          C=C+1\n",
        "        else:\n",
        "          D=D+1\n",
        "    N=vectors_train.todense().shape[0]\n",
        "    if A ==0 :\n",
        "      ll[j][i]=0\n",
        "    else:\n",
        "      if B==0:\n",
        "        ll[j][i]=0\n",
        "      else:\n",
        "        ll[j][i]=math.log(A/(B))\n",
        "#print(ll)\n",
        "llr=[]\n",
        "for i in range((vectors_train.todense().shape[1])):\n",
        "  max=np.max(ll[i, :])\n",
        "  llr.append(max)\n",
        "#print(llr)\n",
        "precis = []\n",
        "f1 = []\n",
        "reca= []\n",
        "for feanum in range(5):\n",
        "\n",
        "  import heapq\n",
        "  lis= llr.copy()\n",
        "  n=(feanum+1)*1000\n",
        "  max_number = heapq.nlargest(n, lis) \n",
        "  max_index = []\n",
        "  for t in max_number:\n",
        "      index = lis.index(t)\n",
        "      max_index.append(index)\n",
        "      lis[index] = 0\n",
        "      \n",
        "  #print(max_number)\n",
        "  #print(max_index)\n",
        "\n",
        "  voca=[]\n",
        "  for i in max_index:\n",
        "    voca.append(vectorizerfeature.get_feature_names()[i])\n",
        "  #print(voca)\n",
        "  voca2 = sorted(set(voca),key=voca.index)\n",
        "\n",
        "  kf = KFold(n_splits=6,shuffle=True)\n",
        "  kf.get_n_splits(X_)\n",
        "  print(kf.split(X_))\n",
        "  accuracy = []\n",
        "  f1_sc = []\n",
        "  recall_sc= []\n",
        "  X_train_ = []\n",
        "  y_train_ = []\n",
        "  X_test_ = []\n",
        "  y_test_ = []\n",
        "  for train_index, test_index in kf.split(X_):\n",
        "\n",
        "    X_train, X_test = X_[train_index], X_[test_index]\n",
        "    y_train, y_test = Y_[train_index].tolist(), Y_[test_index].tolist()\n",
        "    X_train_ = []\n",
        "    X_test_ = []\n",
        "\n",
        "    print(type(X_train))\n",
        "    #print(y_train)\n",
        "    X_train = X_train.tolist()\n",
        "    X_test = X_test.tolist()\n",
        "    vectorizer = CountVectorizer(vocabulary=voca2,binary=True,stop_words = my_stop_words,  tokenizer=StemTokenizer())\n",
        "    vectors_train = vectorizer.fit_transform(X_train)\n",
        "    vectors_test = vectorizer.transform(X_test)\n",
        "    print(vectors_train.shape)\n",
        "    trains = vectors_train.todense()\n",
        "    tests = vectors_test.todense()\n",
        "    print(len(tests))\n",
        "    print(len(y_test))\n",
        "\n",
        "    NBN1 = NBN(trains, y_train)\n",
        "    topic_portion,freq_feature,topics = NBN1.build_NBN()\n",
        "    #print(topics.tolist())\n",
        "    #print(y_test)\n",
        "    accu, result = Accu_eval(tests,y_test,topics)\n",
        "    n=len(y_test)\n",
        "    y_test0=[]\n",
        "    for i in range(n):\n",
        "      y_test0.append(topics.tolist().index([y_test[i]]))\n",
        "\n",
        "    accuracy.append(metrics.precision_score(y_test0, result[0], average='weighted'))\n",
        "    f1_sc.append(metrics.f1_score(y_test0, result[0], average='weighted'))\n",
        "    recall_sc.append(metrics.recall_score(y_test0, result[0], average='weighted'))\n",
        "    print(metrics.classification_report(y_test0, result[0]))\n",
        "\n",
        "  print(np.mean(accuracy))\n",
        "  print(np.mean(f1_sc))\n",
        "  print(np.mean(recall_sc))\n",
        "  precis.append(np.mean(accuracy))\n",
        "  f1.append(np.mean(f1_sc))\n",
        "  reca.append(np.mean(recall_sc))\n",
        "print('precision_score',precis)\n",
        "print('f1_score',f1)\n",
        "print('recall_score',reca)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<generator object _BaseKFold.split at 0x7fa408cd9200>\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(83, 10)\n",
            "17\n",
            "17\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         2\n",
            "           1       0.60      1.00      0.75         3\n",
            "           2       1.00      0.50      0.67         2\n",
            "           3       1.00      1.00      1.00         1\n",
            "           4       0.30      1.00      0.46         3\n",
            "           5       0.00      0.00      0.00         4\n",
            "           6       0.00      0.00      0.00         2\n",
            "\n",
            "    accuracy                           0.47        17\n",
            "   macro avg       0.41      0.50      0.41        17\n",
            "weighted avg       0.34      0.47      0.35        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(83, 10)\n",
            "17\n",
            "17\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.67      0.80         3\n",
            "           1       1.00      1.00      1.00         2\n",
            "           2       1.00      1.00      1.00         2\n",
            "           3       0.00      0.00      0.00         2\n",
            "           4       0.22      1.00      0.36         2\n",
            "           5       0.00      0.00      0.00         1\n",
            "           6       1.00      0.40      0.57         5\n",
            "\n",
            "    accuracy                           0.59        17\n",
            "   macro avg       0.60      0.58      0.53        17\n",
            "weighted avg       0.73      0.59      0.59        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(83, 10)\n",
            "17\n",
            "17\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         2\n",
            "           1       1.00      0.33      0.50         3\n",
            "           2       0.50      1.00      0.67         1\n",
            "           4       0.38      1.00      0.56         5\n",
            "           5       0.00      0.00      0.00         3\n",
            "           6       1.00      0.50      0.67         2\n",
            "           7       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.47        17\n",
            "   macro avg       0.41      0.40      0.34        17\n",
            "weighted avg       0.44      0.47      0.37        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:81: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(83, 10)\n",
            "17\n",
            "17\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         4\n",
            "           1       1.00      0.75      0.86         4\n",
            "           2       1.00      1.00      1.00         1\n",
            "           4       0.45      1.00      0.62         5\n",
            "           6       1.00      0.67      0.80         3\n",
            "\n",
            "    accuracy                           0.65        17\n",
            "   macro avg       0.69      0.68      0.66        17\n",
            "weighted avg       0.60      0.65      0.59        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(84, 10)\n",
            "16\n",
            "16\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.50      0.50         2\n",
            "           1       0.50      0.50      0.50         2\n",
            "           2       1.00      0.50      0.67         2\n",
            "           3       0.00      0.00      0.00         4\n",
            "           4       0.40      0.80      0.53         5\n",
            "           6       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.44        16\n",
            "   macro avg       0.40      0.38      0.37        16\n",
            "weighted avg       0.38      0.44      0.38        16\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(84, 10)\n",
            "16\n",
            "16\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.25      1.00      0.40         1\n",
            "           1       0.00      0.00      0.00         3\n",
            "           2       1.00      0.50      0.67         2\n",
            "           3       0.00      0.00      0.00         3\n",
            "           4       0.55      1.00      0.71         6\n",
            "           5       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.50        16\n",
            "   macro avg       0.30      0.42      0.30        16\n",
            "weighted avg       0.35      0.50      0.37        16\n",
            "\n",
            "0.47140339576001344\n",
            "0.44019980564098216\n",
            "0.5189950980392156\n",
            "<generator object _BaseKFold.split at 0x7fa408cd9200>\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(83, 20)\n",
            "17\n",
            "17\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.25      0.40         4\n",
            "           1       0.67      1.00      0.80         2\n",
            "           2       1.00      1.00      1.00         2\n",
            "           3       1.00      1.00      1.00         1\n",
            "           4       0.44      1.00      0.62         4\n",
            "           5       0.00      0.00      0.00         1\n",
            "           6       1.00      0.33      0.50         3\n",
            "\n",
            "    accuracy                           0.65        17\n",
            "   macro avg       0.73      0.65      0.62        17\n",
            "weighted avg       0.77      0.65      0.60        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(83, 20)\n",
            "17\n",
            "17\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      0.00      0.00         0\n",
            "         1.0       0.67      0.67      0.67         3\n",
            "         2.0       1.00      0.33      0.50         3\n",
            "         3.0       0.00      0.00      0.00         2\n",
            "         4.0       0.62      0.83      0.71         6\n",
            "         5.0       0.00      0.00      0.00         2\n",
            "         6.0       0.33      1.00      0.50         1\n",
            "\n",
            "    accuracy                           0.53        17\n",
            "   macro avg       0.38      0.40      0.34        17\n",
            "weighted avg       0.53      0.53      0.49        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(83, 20)\n",
            "17\n",
            "17\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.40      0.57         5\n",
            "           1       0.67      0.67      0.67         3\n",
            "           2       0.00      0.00      0.00         1\n",
            "           3       0.00      0.00      0.00         1\n",
            "           4       0.30      1.00      0.46         3\n",
            "           5       0.00      0.00      0.00         1\n",
            "           6       1.00      0.33      0.50         3\n",
            "\n",
            "    accuracy                           0.47        17\n",
            "   macro avg       0.42      0.34      0.31        17\n",
            "weighted avg       0.64      0.47      0.46        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(83, 20)\n",
            "17\n",
            "17\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         1\n",
            "           1       1.00      0.75      0.86         4\n",
            "           2       1.00      0.50      0.67         2\n",
            "           3       0.00      0.00      0.00         1\n",
            "           4       0.33      1.00      0.50         4\n",
            "           5       0.00      0.00      0.00         2\n",
            "           6       1.00      0.33      0.50         3\n",
            "\n",
            "    accuracy                           0.53        17\n",
            "   macro avg       0.48      0.37      0.36        17\n",
            "weighted avg       0.61      0.53      0.49        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(84, 20)\n",
            "16\n",
            "16\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      0.00      0.00         1\n",
            "         1.0       0.00      0.00      0.00         2\n",
            "         2.0       0.00      0.00      0.00         0\n",
            "         3.0       1.00      0.50      0.67         2\n",
            "         4.0       0.54      1.00      0.70         7\n",
            "         5.0       0.00      0.00      0.00         2\n",
            "         6.0       1.00      1.00      1.00         1\n",
            "         7.0       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.56        16\n",
            "   macro avg       0.32      0.31      0.30        16\n",
            "weighted avg       0.42      0.56      0.45        16\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:81: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(84, 20)\n",
            "16\n",
            "16\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.33      0.50         3\n",
            "           1       1.00      0.33      0.50         3\n",
            "           2       1.00      1.00      1.00         2\n",
            "           3       0.00      0.00      0.00         3\n",
            "           4       0.17      1.00      0.29         2\n",
            "           5       0.00      0.00      0.00         1\n",
            "           6       0.00      0.00      0.00         2\n",
            "\n",
            "    accuracy                           0.38        16\n",
            "   macro avg       0.45      0.38      0.33        16\n",
            "weighted avg       0.52      0.38      0.35        16\n",
            "\n",
            "0.5830809033014915\n",
            "0.4711370124973066\n",
            "0.5189950980392156\n",
            "<generator object _BaseKFold.split at 0x7fa408cd9200>\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(83, 30)\n",
            "17\n",
            "17\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.25      0.40         4\n",
            "           1       0.00      0.00      0.00         1\n",
            "           2       1.00      0.50      0.67         4\n",
            "           3       0.00      0.00      0.00         2\n",
            "           4       0.25      1.00      0.40         3\n",
            "           5       0.00      0.00      0.00         2\n",
            "           6       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.35        17\n",
            "   macro avg       0.32      0.25      0.21        17\n",
            "weighted avg       0.51      0.35      0.32        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(83, 30)\n",
            "17\n",
            "17\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         1\n",
            "           1       1.00      0.50      0.67         2\n",
            "           3       1.00      1.00      1.00         1\n",
            "           4       0.58      1.00      0.74         7\n",
            "           5       0.00      0.00      0.00         2\n",
            "           6       1.00      0.50      0.67         4\n",
            "\n",
            "    accuracy                           0.71        17\n",
            "   macro avg       0.76      0.67      0.68        17\n",
            "weighted avg       0.71      0.71      0.66        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(83, 30)\n",
            "17\n",
            "17\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      0.33      0.50         3\n",
            "         1.0       1.00      0.75      0.86         4\n",
            "         2.0       0.00      0.00      0.00         0\n",
            "         3.0       0.00      0.00      0.00         2\n",
            "         4.0       0.25      1.00      0.40         3\n",
            "         5.0       0.00      0.00      0.00         1\n",
            "         6.0       0.00      0.00      0.00         3\n",
            "         7.0       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.41        17\n",
            "   macro avg       0.28      0.26      0.22        17\n",
            "weighted avg       0.46      0.41      0.36        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:81: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(83, 30)\n",
            "17\n",
            "17\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.50      0.67         2\n",
            "           1       0.67      0.67      0.67         3\n",
            "           2       1.00      0.67      0.80         3\n",
            "           3       1.00      1.00      1.00         1\n",
            "           4       0.40      0.80      0.53         5\n",
            "           5       0.00      0.00      0.00         2\n",
            "           6       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.59        17\n",
            "   macro avg       0.58      0.52      0.52        17\n",
            "weighted avg       0.59      0.59      0.55        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(84, 30)\n",
            "16\n",
            "16\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      0.50      0.67         2\n",
            "         1.0       1.00      0.25      0.40         4\n",
            "         2.0       1.00      0.33      0.50         3\n",
            "         3.0       0.00      0.00      0.00         2\n",
            "         4.0       0.45      1.00      0.62         5\n",
            "         6.0       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.50        16\n",
            "   macro avg       0.58      0.35      0.37        16\n",
            "weighted avg       0.70      0.50      0.47        16\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(84, 30)\n",
            "16\n",
            "16\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      1.00      0.57         2\n",
            "           1       1.00      0.67      0.80         3\n",
            "           3       0.00      0.00      0.00         2\n",
            "           4       0.43      1.00      0.60         3\n",
            "           5       0.00      0.00      0.00         2\n",
            "           6       1.00      0.50      0.67         4\n",
            "\n",
            "    accuracy                           0.56        16\n",
            "   macro avg       0.47      0.53      0.44        16\n",
            "weighted avg       0.57      0.56      0.50        16\n",
            "\n",
            "0.5903350734233087\n",
            "0.4773919710428031\n",
            "0.5202205882352942\n",
            "<generator object _BaseKFold.split at 0x7fa408cd9200>\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(83, 40)\n",
            "17\n",
            "17\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         3\n",
            "           1       1.00      1.00      1.00         2\n",
            "           2       1.00      1.00      1.00         2\n",
            "           3       1.00      0.50      0.67         2\n",
            "           4       0.42      1.00      0.59         5\n",
            "           5       0.00      0.00      0.00         1\n",
            "           6       0.00      0.00      0.00         2\n",
            "\n",
            "    accuracy                           0.59        17\n",
            "   macro avg       0.49      0.50      0.46        17\n",
            "weighted avg       0.48      0.59      0.49        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(83, 40)\n",
            "17\n",
            "17\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      0.00      0.00         0\n",
            "         1.0       0.50      1.00      0.67         2\n",
            "         2.0       0.00      0.00      0.00         0\n",
            "         3.0       0.00      0.00      0.00         2\n",
            "         4.0       0.62      0.83      0.71         6\n",
            "         5.0       0.00      0.00      0.00         2\n",
            "         6.0       0.00      0.00      0.00         4\n",
            "         7.0       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.41        17\n",
            "   macro avg       0.14      0.23      0.17        17\n",
            "weighted avg       0.28      0.41      0.33        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:81: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(83, 40)\n",
            "17\n",
            "17\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67         1\n",
            "           1       0.50      0.33      0.40         3\n",
            "           2       1.00      0.67      0.80         3\n",
            "           3       0.00      0.00      0.00         2\n",
            "           4       0.38      1.00      0.55         3\n",
            "           5       0.00      0.00      0.00         1\n",
            "           6       1.00      0.50      0.67         4\n",
            "\n",
            "    accuracy                           0.53        17\n",
            "   macro avg       0.48      0.50      0.44        17\n",
            "weighted avg       0.60      0.53      0.50        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(83, 40)\n",
            "17\n",
            "17\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.40      0.57         5\n",
            "           1       0.00      0.00      0.00         3\n",
            "           2       0.00      0.00      0.00         1\n",
            "           3       0.00      0.00      0.00         2\n",
            "           4       0.33      1.00      0.50         5\n",
            "           5       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.41        17\n",
            "   macro avg       0.22      0.23      0.18        17\n",
            "weighted avg       0.39      0.41      0.32        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(84, 40)\n",
            "16\n",
            "16\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.50      0.67         2\n",
            "           1       1.00      0.50      0.67         2\n",
            "           2       1.00      0.33      0.50         3\n",
            "           3       0.00      0.00      0.00         2\n",
            "           4       0.42      1.00      0.59         5\n",
            "           5       0.00      0.00      0.00         1\n",
            "           6       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           0.56        16\n",
            "   macro avg       0.63      0.48      0.49        16\n",
            "weighted avg       0.63      0.56      0.51        16\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(84, 40)\n",
            "16\n",
            "16\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         3\n",
            "           1       1.00      0.20      0.33         5\n",
            "           2       1.00      1.00      1.00         1\n",
            "           4       0.20      1.00      0.33         2\n",
            "           5       0.00      0.00      0.00         3\n",
            "           6       1.00      0.50      0.67         2\n",
            "\n",
            "    accuracy                           0.50        16\n",
            "   macro avg       0.70      0.62      0.56        16\n",
            "weighted avg       0.71      0.50      0.48        16\n",
            "\n",
            "0.5142258986928104\n",
            "0.43706680310270274\n",
            "0.5006127450980392\n",
            "<generator object _BaseKFold.split at 0x7fa408cd9200>\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(83, 50)\n",
            "17\n",
            "17\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         1\n",
            "           1       1.00      1.00      1.00         1\n",
            "           2       0.50      0.50      0.50         2\n",
            "           3       0.00      0.00      0.00         3\n",
            "           4       0.36      1.00      0.53         4\n",
            "           5       0.00      0.00      0.00         2\n",
            "           6       1.00      0.67      0.80         3\n",
            "           7       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.47        17\n",
            "   macro avg       0.36      0.40      0.35        17\n",
            "weighted avg       0.38      0.47      0.38        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:81: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(83, 50)\n",
            "17\n",
            "17\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      0.67      0.80         3\n",
            "         1.0       1.00      0.50      0.67         6\n",
            "         2.0       0.00      0.00      0.00         2\n",
            "         3.0       0.00      0.00      0.00         0\n",
            "         4.0       0.50      1.00      0.67         5\n",
            "         6.0       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           0.65        17\n",
            "   macro avg       0.58      0.53      0.52        17\n",
            "weighted avg       0.74      0.65      0.63        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(83, 50)\n",
            "17\n",
            "17\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         1\n",
            "           1       0.00      0.00      0.00         1\n",
            "           2       1.00      0.25      0.40         4\n",
            "           3       1.00      0.33      0.50         3\n",
            "           4       0.23      0.75      0.35         4\n",
            "           5       0.00      0.00      0.00         3\n",
            "           6       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.29        17\n",
            "   macro avg       0.32      0.19      0.18        17\n",
            "weighted avg       0.47      0.29      0.27        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(83, 50)\n",
            "17\n",
            "17\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.50      0.67         2\n",
            "           1       1.00      0.60      0.75         5\n",
            "           2       1.00      1.00      1.00         1\n",
            "           3       0.00      0.00      0.00         2\n",
            "           4       0.36      1.00      0.53         4\n",
            "           5       0.00      0.00      0.00         1\n",
            "           6       1.00      0.50      0.67         2\n",
            "\n",
            "    accuracy                           0.59        17\n",
            "   macro avg       0.62      0.51      0.52        17\n",
            "weighted avg       0.67      0.59      0.56        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(84, 50)\n",
            "16\n",
            "16\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.33      0.50      0.40         2\n",
            "           1       0.00      0.00      0.00         1\n",
            "           3       0.00      0.00      0.00         2\n",
            "           4       0.36      1.00      0.53         4\n",
            "           5       0.00      0.00      0.00         3\n",
            "           6       0.00      0.00      0.00         4\n",
            "\n",
            "    accuracy                           0.31        16\n",
            "   macro avg       0.12      0.25      0.16        16\n",
            "weighted avg       0.13      0.31      0.18        16\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(84, 50)\n",
            "16\n",
            "16\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.60      0.75         5\n",
            "           1       1.00      0.67      0.80         3\n",
            "           2       0.00      0.00      0.00         1\n",
            "           4       0.50      1.00      0.67         5\n",
            "           6       1.00      0.50      0.67         2\n",
            "\n",
            "    accuracy                           0.69        16\n",
            "   macro avg       0.70      0.55      0.58        16\n",
            "weighted avg       0.78      0.69      0.68        16\n",
            "\n",
            "0.5281098599113304\n",
            "0.45037065071126486\n",
            "0.5\n",
            "[0.47140339576001344, 0.5830809033014915, 0.5903350734233087, 0.5142258986928104, 0.5281098599113304]\n",
            "[0.44019980564098216, 0.4711370124973066, 0.4773919710428031, 0.43706680310270274, 0.45037065071126486]\n",
            "[0.5189950980392156, 0.5189950980392156, 0.5202205882352942, 0.5006127450980392, 0.5]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZkQKQT8_xDc"
      },
      "source": [
        "chi-squared"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EClEiVEL_13C",
        "outputId": "7d93932d-5958-4c9b-fed0-3fde5834f427",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "my_stop_words = text.ENGLISH_STOP_WORDS\n",
        "#import datasets\n",
        "#train = pd.read_csv('train_no_gamenews_computers.csv')\n",
        "train = pd.read_csv('train.csv')\n",
        "n=train.shape[0]\n",
        "#print(n)\n",
        "s=10000\n",
        "skip = sorted(random.sample(range(1,n+1),n-s))\n",
        "#print(len(skip))\n",
        "train = pd.read_csv('train.csv',skiprows=skip)\n",
        "test = pd.read_csv('test.csv')\n",
        "#print(train.shape[0])\n",
        "precis = []\n",
        "f1 = []\n",
        "reca= []\n",
        "for feanum in range(5):\n",
        "  X = pd.DataFrame(train['body'])\n",
        "  Y = pd.DataFrame(train['subreddit'])\n",
        "  X = X['body'].tolist() \n",
        "  Y = Y['subreddit'].tolist()\n",
        "  Y_ = np.array(Y)\n",
        "  X_ = np.array(X)\n",
        "  from sklearn.feature_extraction.text import CountVectorizer\n",
        "  from sklearn import metrics\n",
        "  vectorizerfeature = CountVectorizer(min_df =1,binary=True,ngram_range=(1, 1),stop_words = my_stop_words, tokenizer=StemTokenizer())\n",
        "  vectors_train = vectorizerfeature.fit_transform(X_)\n",
        "  label = Y_.copy()\n",
        "\n",
        "  from sklearn.feature_selection import SelectKBest\n",
        "  from sklearn.feature_selection import chi2\n",
        "\n",
        "  model1 = SelectKBest(chi2, k=(feanum+1)*1000)#选择k个最佳特征\n",
        "  model1.fit_transform(vectors_train.todense(), label)\n",
        "  x=model1.get_support(indices=True)\n",
        "  x=x.tolist()\n",
        "  voca=[]\n",
        "  for i in x:\n",
        "    voca.append(vectorizerfeature.get_feature_names()[i])\n",
        "\n",
        "  voca2 = sorted(set(voca),key=voca.index)\n",
        "  print(len(voca2))\n",
        "\n",
        "  kf = KFold(n_splits=6,shuffle=True)\n",
        "  kf.get_n_splits(X_)\n",
        "  print(kf.split(X_))\n",
        "  accuracy = []\n",
        "  f1_sc = []\n",
        "  recall_sc= []\n",
        "  X_train_ = []\n",
        "  y_train_ = []\n",
        "  X_test_ = []\n",
        "  y_test_ = []\n",
        "  for train_index, test_index in kf.split(X_):\n",
        "\n",
        "    X_train, X_test = X_[train_index], X_[test_index]\n",
        "    y_train, y_test = Y_[train_index].tolist(), Y_[test_index].tolist()\n",
        "    X_train_ = []\n",
        "    X_test_ = []\n",
        "\n",
        "    print(type(X_train))\n",
        "    X_train = X_train.tolist()\n",
        "    X_test = X_test.tolist()\n",
        "    vectorizer = CountVectorizer(vocabulary=voca2,binary=True,ngram_range=(1, 2),stop_words = my_stop_words,  tokenizer=StemTokenizer())\n",
        "    vectors_train = vectorizer.fit_transform(X_train)\n",
        "    vectors_test = vectorizer.transform(X_test)\n",
        "    print(vectors_train.shape)\n",
        "    trains = vectors_train.todense()\n",
        "    tests = vectors_test.todense()\n",
        "    print(len(tests))\n",
        "    print(len(y_test))\n",
        "\n",
        "    NBN1 = NBN(trains, y_train)\n",
        "    topic_portion,freq_feature,topics = NBN1.build_NBN()\n",
        "    print(topics.tolist())\n",
        "    accu, result = Accu_eval(tests,y_test,topics)\n",
        "    n=len(y_test)\n",
        "    y_test0=[]\n",
        "    for i in range(n):\n",
        "      y_test0.append(topics.tolist().index([y_test[i]]))\n",
        "    accuracy.append(metrics.precision_score(y_test0, result[0], average='weighted'))\n",
        "    f1_sc.append(metrics.f1_score(y_test0, result[0], average='weighted'))\n",
        "    recall_sc.append(metrics.recall_score(y_test0, result[0], average='weighted'))\n",
        "    print(metrics.classification_report(y_test0, result[0]))\n",
        "\n",
        "  print(np.mean(accuracy))\n",
        "  print(np.mean(f1_sc))\n",
        "  print(np.mean(recall_sc))\n",
        "  precis.append(np.mean(accuracy))\n",
        "  f1.append(np.mean(f1_sc))\n",
        "  reca.append(np.mean(recall_sc))\n",
        "print('precision_score',precis)\n",
        "print('f1_score',f1)\n",
        "print('recall_score',reca)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10\n",
            "<generator object _BaseKFold.split at 0x7fa40a1689e8>\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(83, 10)\n",
            "17\n",
            "17\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         7\n",
            "           2       0.06      1.00      0.11         1\n",
            "           3       0.00      0.00      0.00         2\n",
            "           4       0.00      0.00      0.00         1\n",
            "           5       0.00      0.00      0.00         2\n",
            "           6       0.00      0.00      0.00         4\n",
            "\n",
            "    accuracy                           0.06        17\n",
            "   macro avg       0.01      0.17      0.02        17\n",
            "weighted avg       0.00      0.06      0.01        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(83, 10)\n",
            "17\n",
            "17\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.20      1.00      0.33         3\n",
            "           1       0.00      0.00      0.00         1\n",
            "           2       0.00      0.00      0.00         4\n",
            "           3       0.00      0.00      0.00         2\n",
            "           4       0.00      0.00      0.00         3\n",
            "           5       0.00      0.00      0.00         2\n",
            "           7       0.00      0.00      0.00         2\n",
            "\n",
            "    accuracy                           0.18        17\n",
            "   macro avg       0.03      0.14      0.05        17\n",
            "weighted avg       0.04      0.18      0.06        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:81: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(83, 10)\n",
            "17\n",
            "17\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.12      1.00      0.21         2\n",
            "           1       0.00      0.00      0.00         2\n",
            "           2       0.00      0.00      0.00         3\n",
            "           3       0.00      0.00      0.00         2\n",
            "           4       0.00      0.00      0.00         4\n",
            "           5       0.00      0.00      0.00         3\n",
            "           6       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.12        17\n",
            "   macro avg       0.02      0.14      0.03        17\n",
            "weighted avg       0.01      0.12      0.02        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(83, 10)\n",
            "17\n",
            "17\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.18      1.00      0.30         3\n",
            "           1       0.00      0.00      0.00         1\n",
            "           2       0.00      0.00      0.00         6\n",
            "           3       0.00      0.00      0.00         2\n",
            "           4       0.00      0.00      0.00         4\n",
            "           6       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.18        17\n",
            "   macro avg       0.03      0.17      0.05        17\n",
            "weighted avg       0.03      0.18      0.05        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(84, 10)\n",
            "16\n",
            "16\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.19      1.00      0.32         3\n",
            "           2       0.00      0.00      0.00         3\n",
            "           3       0.00      0.00      0.00         3\n",
            "           4       0.00      0.00      0.00         3\n",
            "           5       0.00      0.00      0.00         1\n",
            "           6       0.00      0.00      0.00         3\n",
            "\n",
            "    accuracy                           0.19        16\n",
            "   macro avg       0.03      0.17      0.05        16\n",
            "weighted avg       0.04      0.19      0.06        16\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(84, 10)\n",
            "16\n",
            "16\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.19      1.00      0.32         3\n",
            "           1       0.00      0.00      0.00         1\n",
            "           2       0.00      0.00      0.00         4\n",
            "           3       0.00      0.00      0.00         3\n",
            "           4       0.00      0.00      0.00         3\n",
            "           5       0.00      0.00      0.00         2\n",
            "\n",
            "    accuracy                           0.19        16\n",
            "   macro avg       0.03      0.17      0.05        16\n",
            "weighted avg       0.04      0.19      0.06        16\n",
            "\n",
            "0.02567492070357555\n",
            "0.04358158468065588\n",
            "0.15073529411764705\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "20\n",
            "<generator object _BaseKFold.split at 0x7fa40a168ba0>\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(83, 20)\n",
            "17\n",
            "17\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.19      1.00      0.32         3\n",
            "           1       0.00      0.00      0.00         1\n",
            "           2       0.00      0.00      0.00         3\n",
            "           3       0.00      0.00      0.00         3\n",
            "           4       0.00      0.00      0.00         2\n",
            "           5       0.00      0.00      0.00         2\n",
            "           6       0.00      0.00      0.00         2\n",
            "           7       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           0.24        17\n",
            "   macro avg       0.15      0.25      0.16        17\n",
            "weighted avg       0.09      0.24      0.11        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(83, 20)\n",
            "17\n",
            "17\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.06      1.00      0.11         1\n",
            "           2       0.00      0.00      0.00         2\n",
            "           3       0.00      0.00      0.00         6\n",
            "           4       0.00      0.00      0.00         3\n",
            "           5       0.00      0.00      0.00         2\n",
            "           6       0.00      0.00      0.00         3\n",
            "\n",
            "    accuracy                           0.06        17\n",
            "   macro avg       0.01      0.17      0.02        17\n",
            "weighted avg       0.00      0.06      0.01        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(83, 20)\n",
            "17\n",
            "17\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         7\n",
            "           1       0.00      0.00      0.00         1\n",
            "           2       0.12      1.00      0.21         2\n",
            "           3       0.00      0.00      0.00         1\n",
            "           4       0.00      0.00      0.00         4\n",
            "           5       0.00      0.00      0.00         2\n",
            "\n",
            "    accuracy                           0.12        17\n",
            "   macro avg       0.02      0.17      0.04        17\n",
            "weighted avg       0.01      0.12      0.02        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(83, 20)\n",
            "17\n",
            "17\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.12      1.00      0.21         2\n",
            "           2       0.00      0.00      0.00         6\n",
            "           3       0.00      0.00      0.00         1\n",
            "           4       0.00      0.00      0.00         3\n",
            "           5       0.00      0.00      0.00         3\n",
            "           6       0.00      0.00      0.00         2\n",
            "\n",
            "    accuracy                           0.12        17\n",
            "   macro avg       0.02      0.17      0.04        17\n",
            "weighted avg       0.01      0.12      0.02        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(84, 20)\n",
            "16\n",
            "16\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.19      1.00      0.32         3\n",
            "           1       0.00      0.00      0.00         3\n",
            "           2       0.00      0.00      0.00         5\n",
            "           3       0.00      0.00      0.00         1\n",
            "           4       0.00      0.00      0.00         2\n",
            "           5       0.00      0.00      0.00         1\n",
            "           6       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.19        16\n",
            "   macro avg       0.03      0.14      0.05        16\n",
            "weighted avg       0.04      0.19      0.06        16\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(84, 20)\n",
            "16\n",
            "16\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      0.00      0.00         5\n",
            "         1.0       0.00      0.00      0.00         0\n",
            "         2.0       0.20      1.00      0.33         3\n",
            "         3.0       0.00      0.00      0.00         2\n",
            "         4.0       0.00      0.00      0.00         4\n",
            "         6.0       0.00      0.00      0.00         1\n",
            "         7.0       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.19        16\n",
            "   macro avg       0.03      0.14      0.05        16\n",
            "weighted avg       0.04      0.19      0.06        16\n",
            "\n",
            "0.032618313869665516\n",
            "0.04872219355578489\n",
            "0.15073529411764705\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "30\n",
            "<generator object _BaseKFold.split at 0x7fa40a168eb8>\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(83, 30)\n",
            "17\n",
            "17\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.33      0.50         3\n",
            "           2       0.21      1.00      0.35         3\n",
            "           3       0.00      0.00      0.00         4\n",
            "           4       1.00      1.00      1.00         2\n",
            "           5       0.00      0.00      0.00         4\n",
            "           6       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.35        17\n",
            "   macro avg       0.37      0.39      0.31        17\n",
            "weighted avg       0.33      0.35      0.27        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(83, 30)\n",
            "17\n",
            "17\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         3\n",
            "           1       0.00      0.00      0.00         2\n",
            "           2       0.29      1.00      0.44         4\n",
            "           3       0.00      0.00      0.00         3\n",
            "           4       1.00      0.33      0.50         3\n",
            "           5       0.00      0.00      0.00         1\n",
            "           6       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.29        17\n",
            "   macro avg       0.18      0.19      0.13        17\n",
            "weighted avg       0.24      0.29      0.19        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(83, 30)\n",
            "17\n",
            "17\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         6\n",
            "           2       0.12      1.00      0.21         2\n",
            "           3       0.00      0.00      0.00         1\n",
            "           5       0.00      0.00      0.00         5\n",
            "           6       0.00      0.00      0.00         3\n",
            "\n",
            "    accuracy                           0.12        17\n",
            "   macro avg       0.02      0.20      0.04        17\n",
            "weighted avg       0.01      0.12      0.02        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(83, 30)\n",
            "17\n",
            "17\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.33      0.50      0.40         2\n",
            "           1       0.00      0.00      0.00         1\n",
            "           2       0.33      1.00      0.50         3\n",
            "           3       0.00      0.00      0.00         1\n",
            "           4       1.00      0.50      0.67         6\n",
            "           6       0.00      0.00      0.00         2\n",
            "           7       0.00      0.00      0.00         2\n",
            "\n",
            "    accuracy                           0.41        17\n",
            "   macro avg       0.24      0.29      0.22        17\n",
            "weighted avg       0.45      0.41      0.37        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:81: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(84, 30)\n",
            "16\n",
            "16\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         5\n",
            "           1       0.00      0.00      0.00         1\n",
            "           2       0.40      1.00      0.57         4\n",
            "           3       0.00      0.00      0.00         2\n",
            "           4       0.80      1.00      0.89         4\n",
            "\n",
            "    accuracy                           0.50        16\n",
            "   macro avg       0.24      0.40      0.29        16\n",
            "weighted avg       0.30      0.50      0.37        16\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(84, 30)\n",
            "16\n",
            "16\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.15      1.00      0.27         2\n",
            "           1       0.00      0.00      0.00         1\n",
            "           2       0.00      0.00      0.00         5\n",
            "           3       0.00      0.00      0.00         3\n",
            "           4       0.67      0.67      0.67         3\n",
            "           6       0.00      0.00      0.00         2\n",
            "\n",
            "    accuracy                           0.25        16\n",
            "   macro avg       0.14      0.28      0.16        16\n",
            "weighted avg       0.14      0.25      0.16        16\n",
            "\n",
            "0.2474470406563832\n",
            "0.22995754717435654\n",
            "0.32107843137254904\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "40\n",
            "<generator object _BaseKFold.split at 0x7fa40a168bf8>\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(83, 40)\n",
            "17\n",
            "17\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.67      0.62         6\n",
            "           1       0.00      0.00      0.00         2\n",
            "           2       0.22      1.00      0.36         2\n",
            "           3       0.00      0.00      0.00         2\n",
            "           4       1.00      0.50      0.67         2\n",
            "           5       0.00      0.00      0.00         1\n",
            "           6       0.00      0.00      0.00         2\n",
            "\n",
            "    accuracy                           0.41        17\n",
            "   macro avg       0.26      0.31      0.24        17\n",
            "weighted avg       0.35      0.41      0.34        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(83, 40)\n",
            "17\n",
            "17\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         3\n",
            "           1       0.00      0.00      0.00         1\n",
            "           2       0.27      1.00      0.43         3\n",
            "           3       0.00      0.00      0.00         3\n",
            "           4       1.00      0.67      0.80         3\n",
            "           5       0.00      0.00      0.00         2\n",
            "           6       0.00      0.00      0.00         2\n",
            "\n",
            "    accuracy                           0.29        17\n",
            "   macro avg       0.18      0.24      0.18        17\n",
            "weighted avg       0.22      0.29      0.22        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(83, 40)\n",
            "17\n",
            "17\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.09      1.00      0.17         1\n",
            "           2       1.00      0.50      0.67         6\n",
            "           3       0.00      0.00      0.00         3\n",
            "           4       1.00      1.00      1.00         2\n",
            "           5       0.00      0.00      0.00         2\n",
            "           6       0.00      0.00      0.00         2\n",
            "           7       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.35        17\n",
            "   macro avg       0.30      0.36      0.26        17\n",
            "weighted avg       0.48      0.35      0.36        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(83, 40)\n",
            "17\n",
            "17\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.20      1.00      0.33         3\n",
            "           1       0.00      0.00      0.00         1\n",
            "           2       0.00      0.00      0.00         5\n",
            "           3       0.00      0.00      0.00         2\n",
            "           4       0.50      0.33      0.40         3\n",
            "           5       0.00      0.00      0.00         2\n",
            "           6       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.24        17\n",
            "   macro avg       0.10      0.19      0.10        17\n",
            "weighted avg       0.12      0.24      0.13        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(84, 40)\n",
            "16\n",
            "16\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.75      0.67         4\n",
            "           2       0.33      1.00      0.50         2\n",
            "           3       0.00      0.00      0.00         1\n",
            "           4       1.00      0.71      0.83         7\n",
            "           5       0.00      0.00      0.00         1\n",
            "           6       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.62        16\n",
            "   macro avg       0.32      0.41      0.33        16\n",
            "weighted avg       0.63      0.62      0.59        16\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(84, 40)\n",
            "16\n",
            "16\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         4\n",
            "           1       0.00      0.00      0.00         1\n",
            "           2       0.27      1.00      0.43         3\n",
            "           3       0.00      0.00      0.00         3\n",
            "           4       1.00      1.00      1.00         1\n",
            "           5       0.00      0.00      0.00         2\n",
            "           6       0.00      0.00      0.00         1\n",
            "           7       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           0.31        16\n",
            "   macro avg       0.28      0.38      0.30        16\n",
            "weighted avg       0.18      0.31      0.21        16\n",
            "\n",
            "0.32913978722802256\n",
            "0.3077462366065307\n",
            "0.3719362745098039\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "50\n",
            "<generator object _BaseKFold.split at 0x7fa40a168f10>\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(83, 50)\n",
            "17\n",
            "17\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.29      0.36         7\n",
            "           1       0.00      0.00      0.00         2\n",
            "           2       0.20      0.67      0.31         3\n",
            "           3       0.00      0.00      0.00         1\n",
            "           4       0.50      1.00      0.67         1\n",
            "           5       0.00      0.00      0.00         1\n",
            "           6       0.00      0.00      0.00         2\n",
            "\n",
            "    accuracy                           0.29        17\n",
            "   macro avg       0.17      0.28      0.19        17\n",
            "weighted avg       0.27      0.29      0.24        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(83, 50)\n",
            "17\n",
            "17\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.13      0.67      0.22         3\n",
            "           1       0.00      0.00      0.00         1\n",
            "           2       0.00      0.00      0.00         3\n",
            "           3       0.00      0.00      0.00         4\n",
            "           4       1.00      0.50      0.67         2\n",
            "           5       0.00      0.00      0.00         2\n",
            "           6       0.00      0.00      0.00         2\n",
            "\n",
            "    accuracy                           0.18        17\n",
            "   macro avg       0.16      0.17      0.13        17\n",
            "weighted avg       0.14      0.18      0.12        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(83, 50)\n",
            "17\n",
            "17\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         3\n",
            "           1       0.00      0.00      0.00         1\n",
            "           2       0.36      1.00      0.53         4\n",
            "           3       0.00      0.00      0.00         2\n",
            "           4       1.00      0.60      0.75         5\n",
            "           5       0.00      0.00      0.00         1\n",
            "           6       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.41        17\n",
            "   macro avg       0.19      0.23      0.18        17\n",
            "weighted avg       0.38      0.41      0.35        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(83, 50)\n",
            "17\n",
            "17\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.20      0.33      0.25         3\n",
            "           2       0.33      1.00      0.50         3\n",
            "           3       0.00      0.00      0.00         2\n",
            "           4       1.00      0.75      0.86         4\n",
            "           5       0.00      0.00      0.00         3\n",
            "           6       0.00      0.00      0.00         2\n",
            "\n",
            "    accuracy                           0.41        17\n",
            "   macro avg       0.26      0.35      0.27        17\n",
            "weighted avg       0.33      0.41      0.33        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(84, 50)\n",
            "16\n",
            "16\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.10      1.00      0.18         1\n",
            "           1       0.00      0.00      0.00         1\n",
            "           2       1.00      0.40      0.57         5\n",
            "           3       0.00      0.00      0.00         2\n",
            "           4       1.00      0.67      0.80         3\n",
            "           5       0.00      0.00      0.00         3\n",
            "           7       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.31        16\n",
            "   macro avg       0.30      0.30      0.22        16\n",
            "weighted avg       0.51      0.31      0.34        16\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(84, 50)\n",
            "16\n",
            "16\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.43      0.75      0.55         4\n",
            "           2       0.50      1.00      0.67         3\n",
            "           3       0.00      0.00      0.00         3\n",
            "           4       1.00      0.67      0.80         3\n",
            "           6       0.00      0.00      0.00         2\n",
            "           7       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           0.56        16\n",
            "   macro avg       0.49      0.57      0.50        16\n",
            "weighted avg       0.45      0.56      0.47        16\n",
            "\n",
            "0.34633307868601987\n",
            "0.30913412567824333\n",
            "0.36151960784313725\n",
            "[0.02567492070357555, 0.032618313869665516, 0.2474470406563832, 0.32913978722802256, 0.34633307868601987]\n",
            "[0.04358158468065588, 0.04872219355578489, 0.22995754717435654, 0.3077462366065307, 0.30913412567824333]\n",
            "[0.15073529411764705, 0.15073529411764705, 0.32107843137254904, 0.3719362745098039, 0.36151960784313725]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zg1V7vCB_6l8"
      },
      "source": [
        "tfidf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdKiHUdg_-Jk",
        "outputId": "63f63811-cc9a-4a37-da5b-97f2a0d71403",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "my_stop_words = text.ENGLISH_STOP_WORDS\n",
        "#import datasets\n",
        "#train = pd.read_csv('train_no_gamenews_computers.csv')\n",
        "\n",
        "\n",
        "precis = []\n",
        "f1 = []\n",
        "reca= []\n",
        "for feanum in range(5):\n",
        "  train = pd.read_csv('train.csv')\n",
        "  n=train.shape[0]\n",
        "  #print(n)\n",
        "  s=10000\n",
        "  maxFeatures=((feanum+1)*1000)\n",
        "  skip = sorted(random.sample(range(1,n+1),n-s))\n",
        "  #print(len(skip))\n",
        "  train = pd.read_csv('train.csv',skiprows=skip)\n",
        "  test = pd.read_csv('test.csv')\n",
        "  #print(train.shape[0])\n",
        "\n",
        "  X = pd.DataFrame(train['body'])\n",
        "  Y = pd.DataFrame(train['subreddit'])\n",
        "  X = X['body'].tolist() \n",
        "  Y = Y['subreddit'].tolist()\n",
        "  Y_ = np.array(Y)\n",
        "  X_ = np.array(X)\n",
        "\n",
        "  # vectorizer = TfidfVectorizer(max_features=maxFeatures,stop_words = my_stop_words, tokenizer=StemTokenizer())\n",
        "  # vectors_train = vectorizer.fit_transform(X_)\n",
        "  # print(vectors_train.todense())\n",
        "  # print(vectors_train.todense().shape)\n",
        "  kf = KFold(n_splits=6,shuffle=True)\n",
        "  kf.get_n_splits(X_)\n",
        "  #print(kf.split(X_))\n",
        "  accuracy = []\n",
        "  f1_sc = []\n",
        "  recall_sc= []\n",
        "  X_train_ = []\n",
        "  y_train_ = []\n",
        "  X_test_ = []\n",
        "  y_test_ = []\n",
        "  for train_index, test_index in kf.split(X_):\n",
        "\n",
        "    X_train, X_test = X_[train_index], X_[test_index]\n",
        "    y_train, y_test = Y_[train_index].tolist(), Y_[test_index].tolist()\n",
        "    X_train_ = []\n",
        "    X_test_ = []\n",
        "\n",
        "    print(type(X_train))\n",
        "    X_train = X_train.tolist()\n",
        "    X_test = X_test.tolist()\n",
        "    vectorizer = TfidfVectorizer(max_features=maxFeatures,stop_words = my_stop_words, tokenizer=StemTokenizer())\n",
        "    vectors_train = vectorizer.fit_transform(X_train)\n",
        "    vectors_test = vectorizer.transform(X_test)\n",
        "    print(vectors_train.shape)\n",
        "    trains = vectors_train.todense()\n",
        "    tests = vectors_test.todense()\n",
        "    trains = trans_train(trains)\n",
        "    tests = trans_train(tests)\n",
        "    print(len(tests))\n",
        "    print(len(y_test))\n",
        "\n",
        "    NBN1 = NBN(trains, y_train)\n",
        "    topic_portion,freq_feature,topics = NBN1.build_NBN()\n",
        "    print(topics.tolist())\n",
        "    accu, result = Accu_eval(tests,y_test,topics)\n",
        "    n=len(y_test)\n",
        "    y_test0=[]\n",
        "    for i in range(n):\n",
        "      y_test0.append(topics.tolist().index([y_test[i]]))\n",
        "    accuracy.append(metrics.precision_score(y_test0, result[0], average='weighted'))\n",
        "    f1_sc.append(metrics.f1_score(y_test0, result[0], average='weighted'))\n",
        "    recall_sc.append(metrics.recall_score(y_test0, result[0], average='weighted'))\n",
        "    print(metrics.classification_report(y_test0, result[0]))\n",
        "  print(np.mean(accuracy))\n",
        "  print(np.mean(f1_sc))\n",
        "  print(np.mean(recall_sc))\n",
        "  precis.append(np.mean(accuracy))\n",
        "  f1.append(np.mean(f1_sc))\n",
        "  reca.append(np.mean(recall_sc))\n",
        "print('precision_score',precis)\n",
        "print('f1_score',f1)\n",
        "print('recall_score',reca)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(83, 10)\n",
            "17\n",
            "17\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      0.00      0.00         4\n",
            "         1.0       0.50      0.17      0.25         6\n",
            "         2.0       0.50      0.40      0.44         5\n",
            "         3.0       0.00      0.00      0.00         0\n",
            "         4.0       0.20      0.50      0.29         2\n",
            "         5.0       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.24        17\n",
            "   macro avg       0.20      0.18      0.16        17\n",
            "weighted avg       0.35      0.24      0.25        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(83, 10)\n",
            "17\n",
            "17\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.40      0.40      0.40         5\n",
            "         1.0       0.00      0.00      0.00         0\n",
            "         2.0       0.00      0.00      0.00         2\n",
            "         3.0       0.00      0.00      0.00         2\n",
            "         4.0       0.00      0.00      0.00         2\n",
            "         5.0       0.00      0.00      0.00         3\n",
            "         6.0       0.00      0.00      0.00         2\n",
            "         7.0       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.12        17\n",
            "   macro avg       0.05      0.05      0.05        17\n",
            "weighted avg       0.12      0.12      0.12        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(83, 10)\n",
            "17\n",
            "17\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      0.50      0.44         4\n",
            "           1       1.00      1.00      1.00         2\n",
            "           2       0.00      0.00      0.00         2\n",
            "           3       0.50      1.00      0.67         2\n",
            "           4       0.40      0.50      0.44         4\n",
            "           5       0.00      0.00      0.00         1\n",
            "           6       0.00      0.00      0.00         1\n",
            "           7       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.47        17\n",
            "   macro avg       0.29      0.38      0.32        17\n",
            "weighted avg       0.36      0.47      0.41        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(83, 10)\n",
            "17\n",
            "17\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         1\n",
            "           1       0.17      0.50      0.25         2\n",
            "           2       0.00      0.00      0.00         3\n",
            "           3       0.00      0.00      0.00         4\n",
            "           4       0.40      1.00      0.57         2\n",
            "           5       0.00      0.00      0.00         2\n",
            "           6       0.00      0.00      0.00         1\n",
            "           7       0.00      0.00      0.00         2\n",
            "\n",
            "    accuracy                           0.18        17\n",
            "   macro avg       0.07      0.19      0.10        17\n",
            "weighted avg       0.07      0.18      0.10        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(84, 10)\n",
            "16\n",
            "16\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.50      0.50         2\n",
            "           1       1.00      0.67      0.80         3\n",
            "           2       1.00      0.67      0.80         3\n",
            "           3       0.00      0.00      0.00         2\n",
            "           4       0.50      1.00      0.67         3\n",
            "           5       1.00      1.00      1.00         1\n",
            "           6       0.00      0.00      0.00         2\n",
            "\n",
            "    accuracy                           0.56        16\n",
            "   macro avg       0.57      0.55      0.54        16\n",
            "weighted avg       0.59      0.56      0.55        16\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(84, 10)\n",
            "16\n",
            "16\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         1\n",
            "           1       0.33      0.25      0.29         4\n",
            "           2       0.00      0.00      0.00         1\n",
            "           3       0.00      0.00      0.00         2\n",
            "           4       0.40      0.40      0.40         5\n",
            "           5       1.00      1.00      1.00         1\n",
            "           6       0.00      0.00      0.00         1\n",
            "           7       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.25        16\n",
            "   macro avg       0.22      0.21      0.21        16\n",
            "weighted avg       0.27      0.25      0.26        16\n",
            "\n",
            "0.29344362745098035\n",
            "0.2801684562713974\n",
            "0.3020833333333333\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(83, 20)\n",
            "17\n",
            "17\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.67      0.50      0.57         4\n",
            "         1.0       0.00      0.00      0.00         0\n",
            "         2.0       1.00      0.50      0.67         6\n",
            "         3.0       0.00      0.00      0.00         1\n",
            "         4.0       1.00      1.00      1.00         2\n",
            "         5.0       1.00      0.50      0.67         2\n",
            "         6.0       0.33      0.50      0.40         2\n",
            "\n",
            "    accuracy                           0.53        17\n",
            "   macro avg       0.57      0.43      0.47        17\n",
            "weighted avg       0.78      0.53      0.61        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(83, 20)\n",
            "17\n",
            "17\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         2\n",
            "           1       0.40      1.00      0.57         2\n",
            "           2       0.60      0.60      0.60         5\n",
            "           3       0.00      0.00      0.00         3\n",
            "           4       0.25      0.33      0.29         3\n",
            "           5       0.00      0.00      0.00         1\n",
            "           6       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.35        17\n",
            "   macro avg       0.18      0.28      0.21        17\n",
            "weighted avg       0.27      0.35      0.29        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(83, 20)\n",
            "17\n",
            "17\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.14      0.33      0.20         3\n",
            "         1.0       0.40      0.67      0.50         3\n",
            "         2.0       1.00      0.33      0.50         3\n",
            "         3.0       0.00      0.00      0.00         3\n",
            "         4.0       0.00      0.00      0.00         3\n",
            "         5.0       0.00      0.00      0.00         1\n",
            "         6.0       0.00      0.00      0.00         0\n",
            "         7.0       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.24        17\n",
            "   macro avg       0.19      0.17      0.15        17\n",
            "weighted avg       0.27      0.24      0.21        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(83, 20)\n",
            "17\n",
            "17\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.33      0.40         6\n",
            "           1       0.00      0.00      0.00         1\n",
            "           2       0.25      1.00      0.40         1\n",
            "           3       0.00      0.00      0.00         3\n",
            "           4       0.50      0.33      0.40         3\n",
            "           5       0.50      1.00      0.67         1\n",
            "           6       0.00      0.00      0.00         2\n",
            "\n",
            "    accuracy                           0.29        17\n",
            "   macro avg       0.25      0.38      0.27        17\n",
            "weighted avg       0.31      0.29      0.27        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(84, 20)\n",
            "16\n",
            "16\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.33      0.67      0.44         3\n",
            "         1.0       0.50      0.33      0.40         3\n",
            "         2.0       0.50      0.33      0.40         3\n",
            "         3.0       0.00      0.00      0.00         0\n",
            "         4.0       0.33      0.25      0.29         4\n",
            "         5.0       0.00      0.00      0.00         1\n",
            "         6.0       1.00      0.50      0.67         2\n",
            "\n",
            "    accuracy                           0.38        16\n",
            "   macro avg       0.38      0.30      0.31        16\n",
            "weighted avg       0.46      0.38      0.39        16\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(84, 20)\n",
            "16\n",
            "16\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.33      0.50      0.40         4\n",
            "         1.0       0.00      0.00      0.00         2\n",
            "         2.0       0.50      0.25      0.33         4\n",
            "         3.0       0.00      0.00      0.00         2\n",
            "         4.0       0.33      1.00      0.50         1\n",
            "         5.0       0.00      0.00      0.00         0\n",
            "         6.0       1.00      0.50      0.67         2\n",
            "         7.0       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.31        16\n",
            "   macro avg       0.27      0.28      0.24        16\n",
            "weighted avg       0.35      0.31      0.30        16\n",
            "\n",
            "0.40759220354808584\n",
            "0.3465482026143791\n",
            "0.3498774509803922\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(83, 30)\n",
            "17\n",
            "17\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      0.00      0.00         3\n",
            "         1.0       1.00      0.25      0.40         4\n",
            "         2.0       1.00      0.67      0.80         3\n",
            "         3.0       0.00      0.00      0.00         1\n",
            "         4.0       0.25      0.50      0.33         2\n",
            "         5.0       0.00      0.00      0.00         3\n",
            "         6.0       0.00      0.00      0.00         1\n",
            "         7.0       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.24        17\n",
            "   macro avg       0.28      0.18      0.19        17\n",
            "weighted avg       0.44      0.24      0.27        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(83, 30)\n",
            "17\n",
            "17\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         4\n",
            "           1       0.00      0.00      0.00         1\n",
            "           2       0.00      0.00      0.00         4\n",
            "           3       0.33      1.00      0.50         1\n",
            "           4       0.29      1.00      0.44         2\n",
            "           5       0.50      1.00      0.67         1\n",
            "           6       0.00      0.00      0.00         3\n",
            "           7       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.24        17\n",
            "   macro avg       0.14      0.38      0.20        17\n",
            "weighted avg       0.08      0.24      0.12        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(83, 30)\n",
            "17\n",
            "17\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.29      0.67      0.40         3\n",
            "         1.0       0.00      0.00      0.00         0\n",
            "         2.0       1.00      0.40      0.57         5\n",
            "         3.0       0.00      0.00      0.00         2\n",
            "         4.0       0.50      0.50      0.50         2\n",
            "         5.0       0.50      1.00      0.67         1\n",
            "         6.0       0.00      0.00      0.00         3\n",
            "         7.0       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.35        17\n",
            "   macro avg       0.29      0.32      0.27        17\n",
            "weighted avg       0.43      0.35      0.34        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(83, 30)\n",
            "17\n",
            "17\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         1\n",
            "           1       0.00      0.00      0.00         1\n",
            "           2       1.00      0.50      0.67         4\n",
            "           3       0.00      0.00      0.00         3\n",
            "           4       0.33      0.50      0.40         2\n",
            "           5       0.00      0.00      0.00         3\n",
            "           6       0.00      0.00      0.00         2\n",
            "           7       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.18        17\n",
            "   macro avg       0.17      0.12      0.13        17\n",
            "weighted avg       0.27      0.18      0.20        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(84, 30)\n",
            "16\n",
            "16\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.29      0.40      0.33         5\n",
            "         1.0       0.00      0.00      0.00         2\n",
            "         2.0       0.00      0.00      0.00         1\n",
            "         3.0       0.00      0.00      0.00         2\n",
            "         4.0       0.25      0.25      0.25         4\n",
            "         5.0       0.00      0.00      0.00         0\n",
            "         6.0       0.00      0.00      0.00         1\n",
            "         7.0       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.19        16\n",
            "   macro avg       0.07      0.08      0.07        16\n",
            "weighted avg       0.15      0.19      0.17        16\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(84, 30)\n",
            "16\n",
            "16\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.33      0.20      0.25         5\n",
            "           1       0.00      0.00      0.00         3\n",
            "           2       0.25      0.50      0.33         2\n",
            "           3       0.00      0.00      0.00         2\n",
            "           4       0.00      0.00      0.00         2\n",
            "           5       0.00      0.00      0.00         1\n",
            "           6       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.12        16\n",
            "   macro avg       0.08      0.10      0.08        16\n",
            "weighted avg       0.14      0.12      0.12        16\n",
            "\n",
            "0.25304913632119513\n",
            "0.20374990273887336\n",
            "0.21875\n",
            "[0.29344362745098035, 0.40759220354808584, 0.25304913632119513]\n",
            "[0.2801684562713974, 0.3465482026143791, 0.20374990273887336]\n",
            "[0.3020833333333333, 0.3498774509803922, 0.21875]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRT8YLiRABVf"
      },
      "source": [
        "mutual information"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztrgaVgZADel",
        "outputId": "5953fa31-06e7-4cf0-a58b-9320eaeb575c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "my_stop_words = text.ENGLISH_STOP_WORDS\n",
        "#import datasets\n",
        "#train = pd.read_csv('train_no_gamenews_computers.csv')\n",
        "train = pd.read_csv('train.csv')\n",
        "n=train.shape[0]\n",
        "#print(n)\n",
        "s=10000\n",
        "skip = sorted(random.sample(range(1,n+1),n-s))\n",
        "#print(len(skip))\n",
        "train = pd.read_csv('train.csv',skiprows=skip)\n",
        "test = pd.read_csv('test.csv')\n",
        "#print(train.shape[0])\n",
        "\n",
        "X = pd.DataFrame(train['body'])\n",
        "Y = pd.DataFrame(train['subreddit'])\n",
        "X = X['body'].tolist() \n",
        "Y = Y['subreddit'].tolist()\n",
        "Y_ = np.array(Y)\n",
        "X_ = np.array(X)\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn import metrics\n",
        "vectorizerfeature = CountVectorizer(min_df =1,binary=True,stop_words = my_stop_words, tokenizer=StemTokenizer())\n",
        "vectors_train = vectorizerfeature.fit_transform(X_)\n",
        "label = Y_\n",
        "mutual_info=[]\n",
        "for i in range(vectors_train.todense().shape[1]):\n",
        "  x=vectors_train.todense()\n",
        "  x0 = x[:, i]\n",
        "  x0=np.array(x0).flatten()\n",
        "  # 计算各特征与label的互信息\n",
        "  mutual_info.append(metrics.mutual_info_score(x0, label))\n",
        "#print(mutual_info)\n",
        "precis = []\n",
        "f1 = []\n",
        "reca= []\n",
        "for feanum in range(5):\n",
        "  import heapq\n",
        "  lis= mutual_info.copy()\n",
        "  n=(feanum+1)*1000\n",
        "  max_number = heapq.nlargest(n, lis) \n",
        "  max_index = []\n",
        "  for t in max_number:\n",
        "      index = lis.index(t)\n",
        "      max_index.append(index)\n",
        "      lis[index] = 0\n",
        "      \n",
        "  #print(max_number)\n",
        "  #print(max_index)\n",
        "\n",
        "  voca=[]\n",
        "  for i in max_index:\n",
        "    voca.append(vectorizerfeature.get_feature_names()[i])\n",
        "  #print(voca)\n",
        "  voca2 = sorted(set(voca),key=voca.index)\n",
        "\n",
        "  vectorizer = CountVectorizer(vocabulary=voca2,binary=True,stop_words = my_stop_words, tokenizer=StemTokenizer())\n",
        "  vectors_train = vectorizer.fit_transform(X_)\n",
        "  vectors_train.todense()\n",
        "\n",
        "  kf = KFold(n_splits=6,shuffle=True)\n",
        "  kf.get_n_splits(X_)\n",
        "  #print(kf.split(X_))\n",
        "  accuracy = []\n",
        "  f1_sc = []\n",
        "  recall_sc= []\n",
        "  X_train_ = []\n",
        "  y_train_ = []\n",
        "  X_test_ = []\n",
        "  y_test_ = []\n",
        "  for train_index, test_index in kf.split(X_):\n",
        "\n",
        "    X_train, X_test = X_[train_index], X_[test_index]\n",
        "    y_train, y_test = Y_[train_index].tolist(), Y_[test_index].tolist()\n",
        "    X_train_ = []\n",
        "    X_test_ = []\n",
        "\n",
        "    print(type(X_train))\n",
        "    X_train = X_train.tolist()\n",
        "    X_test = X_test.tolist()\n",
        "    vectorizer = CountVectorizer(vocabulary=voca2,binary=True, tokenizer=StemTokenizer())\n",
        "    vectors_train = vectorizer.fit_transform(X_train)\n",
        "    vectors_test = vectorizer.transform(X_test)\n",
        "    print(vectors_train.shape)\n",
        "    trains = vectors_train.todense()\n",
        "    tests = vectors_test.todense()\n",
        "    print(len(tests))\n",
        "    print(len(y_test))\n",
        "\n",
        "    NBN1 = NBN(trains, y_train)\n",
        "    topic_portion,freq_feature,topics = NBN1.build_NBN()\n",
        "    print(topics.tolist())\n",
        "    accu, result = Accu_eval(tests,y_test,topics)\n",
        "    n=len(y_test)\n",
        "    y_test0=[]\n",
        "    for i in range(n):\n",
        "      y_test0.append(topics.tolist().index([y_test[i]]))\n",
        "    accuracy.append(metrics.precision_score(y_test0, result[0], average='weighted'))\n",
        "    f1_sc.append(metrics.f1_score(y_test0, result[0], average='weighted'))\n",
        "    recall_sc.append(metrics.recall_score(y_test0, result[0], average='weighted'))\n",
        "    print(metrics.classification_report(y_test0, result[0]))\n",
        "  print(np.mean(accuracy))\n",
        "  print(np.mean(f1_sc))\n",
        "  print(np.mean(recall_sc))\n",
        "  precis.append(np.mean(accuracy))\n",
        "  f1.append(np.mean(f1_sc))\n",
        "  reca.append(np.mean(recall_sc))\n",
        "print('precision_score',precis)\n",
        "print('f1_score',f1)\n",
        "print('recall_score',reca)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "(83, 10)\n",
            "17\n",
            "17\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.40      0.40      0.40         5\n",
            "         1.0       1.00      1.00      1.00         3\n",
            "         2.0       0.00      0.00      0.00         2\n",
            "         3.0       0.00      0.00      0.00         0\n",
            "         4.0       1.00      0.67      0.80         3\n",
            "         5.0       0.00      0.00      0.00         2\n",
            "         6.0       0.00      0.00      0.00         2\n",
            "\n",
            "    accuracy                           0.41        17\n",
            "   macro avg       0.34      0.30      0.31        17\n",
            "weighted avg       0.47      0.41      0.44        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(83, 10)\n",
            "17\n",
            "17\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.33      0.50      0.40         2\n",
            "           1       1.00      1.00      1.00         2\n",
            "           2       0.83      1.00      0.91         5\n",
            "           3       0.40      1.00      0.57         2\n",
            "           4       1.00      1.00      1.00         1\n",
            "           5       0.00      0.00      0.00         2\n",
            "           6       0.00      0.00      0.00         2\n",
            "           7       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.65        17\n",
            "   macro avg       0.45      0.56      0.49        17\n",
            "weighted avg       0.51      0.65      0.56        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:81: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(83, 10)\n",
            "17\n",
            "17\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.09      1.00      0.17         1\n",
            "           1       1.00      0.50      0.67         4\n",
            "           2       1.00      0.75      0.86         4\n",
            "           3       0.00      0.00      0.00         3\n",
            "           4       1.00      0.50      0.67         2\n",
            "           5       0.00      0.00      0.00         1\n",
            "           6       0.00      0.00      0.00         2\n",
            "\n",
            "    accuracy                           0.41        17\n",
            "   macro avg       0.44      0.39      0.34        17\n",
            "weighted avg       0.59      0.41      0.45        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(83, 10)\n",
            "17\n",
            "17\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.29      1.00      0.44         2\n",
            "           1       1.00      0.80      0.89         5\n",
            "           2       1.00      0.75      0.86         4\n",
            "           3       0.00      0.00      0.00         4\n",
            "           4       0.67      1.00      0.80         2\n",
            "\n",
            "    accuracy                           0.65        17\n",
            "   macro avg       0.59      0.71      0.60        17\n",
            "weighted avg       0.64      0.65      0.61        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(84, 10)\n",
            "16\n",
            "16\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.80      0.80         5\n",
            "           1       1.00      0.50      0.67         2\n",
            "           2       0.67      0.67      0.67         3\n",
            "           3       0.43      0.60      0.50         5\n",
            "           4       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.62        16\n",
            "   macro avg       0.58      0.51      0.53        16\n",
            "weighted avg       0.63      0.62      0.61        16\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(84, 10)\n",
            "16\n",
            "16\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.33      0.33      0.33         3\n",
            "           1       1.00      0.67      0.80         3\n",
            "           2       1.00      0.83      0.91         6\n",
            "           3       0.00      0.00      0.00         1\n",
            "           4       1.00      1.00      1.00         1\n",
            "           6       0.00      0.00      0.00         2\n",
            "\n",
            "    accuracy                           0.56        16\n",
            "   macro avg       0.56      0.47      0.51        16\n",
            "weighted avg       0.69      0.56      0.62        16\n",
            "\n",
            "0.5891499023851964\n",
            "0.54670417409388\n",
            "0.5508578431372549\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "(83, 20)\n",
            "17\n",
            "17\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.33      0.50      0.40         4\n",
            "           1       0.50      1.00      0.67         2\n",
            "           2       1.00      0.83      0.91         6\n",
            "           3       1.00      0.33      0.50         3\n",
            "           5       0.00      0.00      0.00         1\n",
            "           6       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.59        17\n",
            "   macro avg       0.47      0.44      0.41        17\n",
            "weighted avg       0.67      0.59      0.58        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(83, 20)\n",
            "17\n",
            "17\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.57      1.00      0.73         4\n",
            "         1.0       0.50      1.00      0.67         2\n",
            "         2.0       1.00      0.50      0.67         4\n",
            "         3.0       1.00      0.33      0.50         3\n",
            "         4.0       1.00      0.67      0.80         3\n",
            "         5.0       0.00      0.00      0.00         0\n",
            "         6.0       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.65        17\n",
            "   macro avg       0.58      0.50      0.48        17\n",
            "weighted avg       0.78      0.65      0.64        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(83, 20)\n",
            "17\n",
            "17\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.25      1.00      0.40         1\n",
            "         1.0       1.00      0.83      0.91         6\n",
            "         2.0       1.00      0.80      0.89         5\n",
            "         3.0       1.00      0.50      0.67         2\n",
            "         4.0       1.00      0.50      0.67         2\n",
            "         5.0       0.00      0.00      0.00         1\n",
            "         6.0       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.71        17\n",
            "   macro avg       0.61      0.52      0.50        17\n",
            "weighted avg       0.90      0.71      0.76        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(83, 20)\n",
            "17\n",
            "17\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      1.00      0.80         4\n",
            "           1       0.50      1.00      0.67         2\n",
            "           2       0.40      1.00      0.57         2\n",
            "           3       1.00      0.50      0.67         4\n",
            "           4       0.00      0.00      0.00         1\n",
            "           5       0.00      0.00      0.00         1\n",
            "           6       0.00      0.00      0.00         2\n",
            "           7       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.59        17\n",
            "   macro avg       0.32      0.44      0.34        17\n",
            "weighted avg       0.50      0.59      0.49        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:81: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(84, 20)\n",
            "16\n",
            "16\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.25      1.00      0.40         1\n",
            "           1       0.75      0.75      0.75         4\n",
            "           2       1.00      0.50      0.67         4\n",
            "           3       0.25      1.00      0.40         1\n",
            "           4       1.00      0.67      0.80         3\n",
            "           5       0.00      0.00      0.00         1\n",
            "           6       0.00      0.00      0.00         2\n",
            "\n",
            "    accuracy                           0.56        16\n",
            "   macro avg       0.46      0.56      0.43        16\n",
            "weighted avg       0.66      0.56      0.55        16\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(84, 20)\n",
            "16\n",
            "16\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.50      0.57         4\n",
            "           1       0.50      1.00      0.67         3\n",
            "           2       1.00      1.00      1.00         3\n",
            "           3       0.00      0.00      0.00         2\n",
            "           4       1.00      1.00      1.00         1\n",
            "           5       0.00      0.00      0.00         1\n",
            "           6       0.00      0.00      0.00         2\n",
            "\n",
            "    accuracy                           0.56        16\n",
            "   macro avg       0.45      0.50      0.46        16\n",
            "weighted avg       0.51      0.56      0.52        16\n",
            "\n",
            "0.6683239962651727\n",
            "0.5904890996802762\n",
            "0.6090686274509804\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "(83, 30)\n",
            "17\n",
            "17\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.75      0.67         4\n",
            "           1       0.67      1.00      0.80         2\n",
            "           2       1.00      0.80      0.89         5\n",
            "           3       1.00      1.00      1.00         1\n",
            "           4       1.00      0.75      0.86         4\n",
            "           6       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           0.82        17\n",
            "   macro avg       0.88      0.88      0.87        17\n",
            "weighted avg       0.87      0.82      0.83        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n",
            "(83, 30)\n",
            "17\n",
            "17\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.33      0.40         3\n",
            "           1       0.67      1.00      0.80         4\n",
            "           2       0.75      1.00      0.86         3\n",
            "           3       0.75      1.00      0.86         3\n",
            "           4       1.00      0.50      0.67         2\n",
            "           6       0.00      0.00      0.00         1\n",
            "           7       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.71        17\n",
            "   macro avg       0.52      0.55      0.51        17\n",
            "weighted avg       0.63      0.71      0.64        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:81: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(83, 30)\n",
            "17\n",
            "17\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.33      1.00      0.50         2\n",
            "           1       0.57      1.00      0.73         4\n",
            "           2       1.00      0.40      0.57         5\n",
            "           3       1.00      0.50      0.67         4\n",
            "           5       0.00      0.00      0.00         1\n",
            "           6       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.59        17\n",
            "   macro avg       0.48      0.48      0.41        17\n",
            "weighted avg       0.70      0.59      0.55        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(83, 30)\n",
            "17\n",
            "17\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67         2\n",
            "           1       0.25      0.50      0.33         2\n",
            "           2       1.00      1.00      1.00         4\n",
            "           3       0.75      0.60      0.67         5\n",
            "           4       1.00      1.00      1.00         1\n",
            "           6       0.00      0.00      0.00         3\n",
            "\n",
            "    accuracy                           0.65        17\n",
            "   macro avg       0.58      0.68      0.61        17\n",
            "weighted avg       0.60      0.65      0.61        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(84, 30)\n",
            "16\n",
            "16\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.75      0.67         4\n",
            "           1       0.50      1.00      0.67         3\n",
            "           2       1.00      0.67      0.80         3\n",
            "           3       0.00      0.00      0.00         1\n",
            "           4       1.00      0.50      0.67         2\n",
            "           5       0.00      0.00      0.00         2\n",
            "           6       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.56        16\n",
            "   macro avg       0.44      0.42      0.40        16\n",
            "weighted avg       0.56      0.56      0.53        16\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(84, 30)\n",
            "16\n",
            "16\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.33      0.67      0.44         3\n",
            "           1       0.75      0.75      0.75         4\n",
            "           2       1.00      0.75      0.86         4\n",
            "           3       0.50      1.00      0.67         1\n",
            "           4       1.00      1.00      1.00         1\n",
            "           5       0.00      0.00      0.00         2\n",
            "           6       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.62        16\n",
            "   macro avg       0.51      0.60      0.53        16\n",
            "weighted avg       0.59      0.62      0.59        16\n",
            "\n",
            "0.6583566760037348\n",
            "0.6247545482839602\n",
            "0.6587009803921569\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "(83, 40)\n",
            "17\n",
            "17\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      1.00      0.83         5\n",
            "           1       0.50      1.00      0.67         3\n",
            "           2       1.00      0.50      0.67         4\n",
            "           3       0.00      0.00      0.00         1\n",
            "           4       1.00      1.00      1.00         1\n",
            "           5       0.00      0.00      0.00         2\n",
            "           6       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.65        17\n",
            "   macro avg       0.46      0.50      0.45        17\n",
            "weighted avg       0.59      0.65      0.58        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(83, 40)\n",
            "17\n",
            "17\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      1.00      0.75         3\n",
            "           1       0.60      1.00      0.75         3\n",
            "           2       1.00      0.75      0.86         4\n",
            "           3       1.00      1.00      1.00         3\n",
            "           4       1.00      0.50      0.67         2\n",
            "           6       0.00      0.00      0.00         2\n",
            "\n",
            "    accuracy                           0.76        17\n",
            "   macro avg       0.70      0.71      0.67        17\n",
            "weighted avg       0.74      0.76      0.72        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(83, 40)\n",
            "17\n",
            "17\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         1\n",
            "           1       0.17      1.00      0.29         1\n",
            "           2       1.00      0.86      0.92         7\n",
            "           3       1.00      0.33      0.50         3\n",
            "           4       0.67      0.50      0.57         4\n",
            "           7       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.65        17\n",
            "   macro avg       0.64      0.62      0.55        17\n",
            "weighted avg       0.81      0.65      0.68        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:81: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(83, 40)\n",
            "17\n",
            "17\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.33      1.00      0.50         2\n",
            "           1       0.75      0.60      0.67         5\n",
            "           2       1.00      1.00      1.00         3\n",
            "           3       0.33      0.50      0.40         2\n",
            "           4       0.00      0.00      0.00         1\n",
            "           5       0.00      0.00      0.00         1\n",
            "           6       0.00      0.00      0.00         3\n",
            "\n",
            "    accuracy                           0.53        17\n",
            "   macro avg       0.35      0.44      0.37        17\n",
            "weighted avg       0.48      0.53      0.48        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(84, 40)\n",
            "16\n",
            "16\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.67      0.50      0.57         4\n",
            "         1.0       0.50      0.67      0.57         3\n",
            "         2.0       1.00      1.00      1.00         3\n",
            "         3.0       0.75      0.75      0.75         4\n",
            "         4.0       0.00      0.00      0.00         0\n",
            "         5.0       0.00      0.00      0.00         1\n",
            "         6.0       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           0.69        16\n",
            "   macro avg       0.56      0.56      0.56        16\n",
            "weighted avg       0.70      0.69      0.69        16\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(84, 40)\n",
            "16\n",
            "16\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.33      0.40         3\n",
            "           1       1.00      1.00      1.00         4\n",
            "           2       1.00      0.33      0.50         3\n",
            "           3       0.33      1.00      0.50         2\n",
            "           4       1.00      1.00      1.00         2\n",
            "           5       0.00      0.00      0.00         1\n",
            "           6       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           0.69        16\n",
            "   macro avg       0.69      0.67      0.63        16\n",
            "weighted avg       0.76      0.69      0.67        16\n",
            "\n",
            "0.6801937441643324\n",
            "0.6354685143288084\n",
            "0.6605392156862745\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "(83, 50)\n",
            "17\n",
            "17\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.33      0.50      0.40         2\n",
            "         1.0       1.00      0.57      0.73         7\n",
            "         2.0       1.00      0.67      0.80         3\n",
            "         3.0       0.00      0.00      0.00         0\n",
            "         4.0       0.00      0.00      0.00         3\n",
            "         6.0       1.00      0.50      0.67         2\n",
            "\n",
            "    accuracy                           0.47        17\n",
            "   macro avg       0.56      0.37      0.43        17\n",
            "weighted avg       0.75      0.47      0.57        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(83, 50)\n",
            "17\n",
            "17\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67         2\n",
            "           1       0.50      1.00      0.67         3\n",
            "           2       1.00      0.67      0.80         6\n",
            "           3       0.00      0.00      0.00         2\n",
            "           4       1.00      1.00      1.00         1\n",
            "           5       0.00      0.00      0.00         1\n",
            "           6       1.00      0.50      0.67         2\n",
            "\n",
            "    accuracy                           0.65        17\n",
            "   macro avg       0.57      0.60      0.54        17\n",
            "weighted avg       0.68      0.65      0.62        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(83, 50)\n",
            "17\n",
            "17\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.67      0.67         6\n",
            "           1       0.33      1.00      0.50         1\n",
            "           2       1.00      0.67      0.80         3\n",
            "           3       0.80      1.00      0.89         4\n",
            "           4       1.00      1.00      1.00         1\n",
            "           5       0.00      0.00      0.00         1\n",
            "           6       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.71        17\n",
            "   macro avg       0.54      0.62      0.55        17\n",
            "weighted avg       0.68      0.71      0.67        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(83, 50)\n",
            "17\n",
            "17\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.67      0.57         3\n",
            "           1       0.60      1.00      0.75         3\n",
            "           2       1.00      1.00      1.00         5\n",
            "           3       1.00      0.67      0.80         3\n",
            "           4       1.00      1.00      1.00         1\n",
            "           5       0.00      0.00      0.00         2\n",
            "\n",
            "    accuracy                           0.76        17\n",
            "   macro avg       0.68      0.72      0.69        17\n",
            "weighted avg       0.72      0.76      0.73        17\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(84, 50)\n",
            "16\n",
            "16\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      1.00      0.57         2\n",
            "           1       0.75      1.00      0.86         3\n",
            "           2       1.00      1.00      1.00         3\n",
            "           3       1.00      0.75      0.86         4\n",
            "           4       0.00      0.00      0.00         2\n",
            "           6       1.00      0.50      0.67         2\n",
            "\n",
            "    accuracy                           0.75        16\n",
            "   macro avg       0.69      0.71      0.66        16\n",
            "weighted avg       0.75      0.75      0.72        16\n",
            "\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(84, 50)\n",
            "16\n",
            "16\n",
            "[['rpg'], ['anime'], ['datascience'], ['hardware'], ['cars'], ['gamernews'], ['gamedev'], ['computers']]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67         3\n",
            "           1       1.00      0.50      0.67         2\n",
            "           2       1.00      0.75      0.86         4\n",
            "           3       1.00      1.00      1.00         2\n",
            "           4       0.50      1.00      0.67         2\n",
            "           5       0.00      0.00      0.00         1\n",
            "           6       0.00      0.00      0.00         1\n",
            "           7       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.69        16\n",
            "   macro avg       0.50      0.53      0.48        16\n",
            "weighted avg       0.66      0.69      0.63        16\n",
            "\n",
            "0.705484068627451\n",
            "0.655199933508757\n",
            "0.6709558823529411\n",
            "[0.5891499023851964, 0.6683239962651727, 0.6583566760037348, 0.6801937441643324, 0.705484068627451]\n",
            "[0.54670417409388, 0.5904890996802762, 0.6247545482839602, 0.6354685143288084, 0.655199933508757]\n",
            "[0.5508578431372549, 0.6090686274509804, 0.6587009803921569, 0.6605392156862745, 0.6709558823529411]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:81: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}